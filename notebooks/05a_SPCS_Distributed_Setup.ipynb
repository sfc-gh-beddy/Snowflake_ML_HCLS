{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ðŸš€ Snowflake Container Runtime for Distributed ML\n",
        "\n",
        "This notebook sets up **true distributed training** using Snowflake's **Container Runtime** with compute pools - **no Docker builds required!**\n",
        "\n",
        "## ðŸ—ï¸ **Simplified Infrastructure (Container Runtime):**\n",
        "1. **ðŸ–¥ï¸ Compute Pools** - Multi-node clusters for distributed training\n",
        "2. **ðŸ“¦ Pre-built Images** - Use Anaconda/public ML images via Container Runtime\n",
        "3. **âš¡ Distributed Training** - Multi-node XGBoost, Ray ML, and more\n",
        "4. **ðŸ“Š Resource Management** - Auto-scaling and load balancing\n",
        "5. **ðŸ”— Integration** - Seamless connection to Snowflake ML Registry\n",
        "\n",
        "## ðŸ“‹ **Prerequisites:**\n",
        "- SPCS enabled in your Snowflake account\n",
        "- ACCOUNTADMIN privileges for compute pool creation\n",
        "- **No Docker needed** - uses Container Runtime!\n",
        "\n",
        "## ðŸ’¡ **Container Runtime Benefits:**\n",
        "- âœ… **No manual Docker builds**\n",
        "- âœ… **Pre-built ML images** from Anaconda\n",
        "- âœ… **Snowflake UI configuration**\n",
        "- âœ… **Automatic dependency management**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ Added to Python path: /Users/beddy/Desktop/Github/Snowflake_ML_HCLS/notebooks/../src\n",
            "ðŸ”„ Reusing existing Snowflake session\n",
            "âœ… Snowflake connection established for SPCS setup\n",
            "ðŸ—ï¸ Ready to configure distributed training infrastructure\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup for SPCS\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Fix path for snowflake_connection module\n",
        "current_dir = os.getcwd()\n",
        "if \"notebooks\" in current_dir:\n",
        "    src_path = os.path.join(current_dir, \"..\", \"src\")\n",
        "else:\n",
        "    src_path = os.path.join(current_dir, \"src\")\n",
        "\n",
        "sys.path.append(src_path)\n",
        "print(f\"ðŸ“ Added to Python path: {src_path}\")\n",
        "\n",
        "from snowflake_connection import get_session\n",
        "\n",
        "# Get Snowflake session with admin privileges\n",
        "session = get_session()\n",
        "print(\"âœ… Snowflake connection established for SPCS setup\")\n",
        "print(\"ðŸ—ï¸ Ready to configure distributed training infrastructure\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ–¥ï¸ Setting up compute pools for distributed ML training...\n",
            "âœ… GPU compute pool created: ML_DISTRIBUTED_GPU_POOL\n",
            "âœ… CPU compute pool created: ML_DISTRIBUTED_CPU_POOL\n",
            "\n",
            "ðŸ“Š Available compute pools (4 total):\n",
            "   ðŸ–¥ï¸ ML_DISTRIBUTED_CPU_POOL - CPU_X64_S (SUSPENDED)\n",
            "   ðŸ–¥ï¸ ML_DISTRIBUTED_GPU_POOL - GPU_NV_S (SUSPENDED)\n"
          ]
        }
      ],
      "source": [
        "# 1. Create Compute Pools for Distributed Training\n",
        "print(\"ðŸ–¥ï¸ Setting up compute pools for distributed ML training...\")\n",
        "\n",
        "# Create GPU-enabled compute pool for intensive ML workloads\n",
        "gpu_pool_sql = \"\"\"\n",
        "CREATE COMPUTE POOL IF NOT EXISTS ML_DISTRIBUTED_GPU_POOL\n",
        "MIN_NODES = 1\n",
        "MAX_NODES = 8\n",
        "INSTANCE_FAMILY = GPU_NV_S\n",
        "AUTO_RESUME = TRUE\n",
        "AUTO_SUSPEND_SECS = 300\n",
        "COMMENT = 'GPU compute pool for distributed ML training with Ray/XGBoost'\n",
        "\"\"\"\n",
        "\n",
        "# Create CPU compute pool for general distributed training\n",
        "cpu_pool_sql = \"\"\"\n",
        "CREATE COMPUTE POOL IF NOT EXISTS ML_DISTRIBUTED_CPU_POOL\n",
        "MIN_NODES = 2\n",
        "MAX_NODES = 16\n",
        "INSTANCE_FAMILY = CPU_X64_S\n",
        "AUTO_RESUME = TRUE\n",
        "AUTO_SUSPEND_SECS = 300\n",
        "COMMENT = 'CPU compute pool for distributed ML training and data processing'\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    # Execute compute pool creation\n",
        "    session.sql(gpu_pool_sql).collect()\n",
        "    print(\"âœ… GPU compute pool created: ML_DISTRIBUTED_GPU_POOL\")\n",
        "    \n",
        "    session.sql(cpu_pool_sql).collect()\n",
        "    print(\"âœ… CPU compute pool created: ML_DISTRIBUTED_CPU_POOL\")\n",
        "    \n",
        "    # List compute pools\n",
        "    pools = session.sql(\"SHOW COMPUTE POOLS\").collect()\n",
        "    print(f\"\\nðŸ“Š Available compute pools ({len(pools)} total):\")\n",
        "    for pool in pools:\n",
        "        if 'ML_DISTRIBUTED' in pool['name']:\n",
        "            print(f\"   ðŸ–¥ï¸ {pool['name']} - {pool['instance_family']} ({pool['state']})\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Compute pool setup error: {e}\")\n",
        "    print(\"ðŸ’¡ Note: SPCS requires ACCOUNTADMIN privileges and may need to be enabled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¯ Compute pools are ready for distributed ML training!\n",
            "\\nðŸ“Š Available compute pools for distributed training:\n",
            "   ðŸ–¥ï¸ ML_DISTRIBUTED_CPU_POOL\n",
            "      Instance Family: CPU_X64_S\n",
            "      State: SUSPENDED\n",
            "      Min/Max Nodes: 2/16\n",
            "\n",
            "   ðŸ–¥ï¸ ML_DISTRIBUTED_GPU_POOL\n",
            "      Instance Family: GPU_NV_S\n",
            "      State: SUSPENDED\n",
            "      Min/Max Nodes: 1/8\n",
            "\n",
            "âœ… Compute pools ready for distributed training!\n",
            "ðŸ’¡ Snowflake ML APIs will automatically use these pools\n",
            "ðŸš€ No additional container setup needed\n",
            "\\nðŸŽ¯ Ready for Distributed Training!\n",
            "ðŸ“‹ What's set up:\n",
            "   ðŸ–¥ï¸ Multi-node compute pools (CPU + GPU)\n",
            "   âš¡ Auto-scaling from 1-16 nodes\n",
            "   ðŸ”— Direct integration with Snowflake ML APIs\n",
            "   ðŸ“Š Native distributed XGBoost support\n",
            "\\nðŸ“š Next: Run 05b_True_Distributed_Training.ipynb\n"
          ]
        }
      ],
      "source": [
        "# 3. Verify Compute Pool Setup for Distributed Training\n",
        "print(\"ðŸŽ¯ Compute pools are ready for distributed ML training!\")\n",
        "\n",
        "# Check compute pool status\n",
        "try:\n",
        "    pools = session.sql(\"SHOW COMPUTE POOLS\").collect()\n",
        "    print(\"\\\\nðŸ“Š Available compute pools for distributed training:\")\n",
        "    \n",
        "    ml_pools = []\n",
        "    for pool in pools:\n",
        "        if 'ML_DISTRIBUTED' in pool['name']:\n",
        "            ml_pools.append(pool)\n",
        "            print(f\"   ðŸ–¥ï¸ {pool['name']}\")\n",
        "            print(f\"      Instance Family: {pool['instance_family']}\")\n",
        "            print(f\"      State: {pool['state']}\")\n",
        "            print(f\"      Min/Max Nodes: {pool['min_nodes']}/{pool['max_nodes']}\")\n",
        "            print()\n",
        "    \n",
        "    if len(ml_pools) >= 1:\n",
        "        print(\"âœ… Compute pools ready for distributed training!\")\n",
        "        print(\"ðŸ’¡ Snowflake ML APIs will automatically use these pools\")\n",
        "        print(\"ðŸš€ No additional container setup needed\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No ML compute pools found - check previous cell\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error checking compute pools: {e}\")\n",
        "\n",
        "print(\"\\\\nðŸŽ¯ Ready for Distributed Training!\")\n",
        "print(\"ðŸ“‹ What's set up:\")\n",
        "print(\"   ðŸ–¥ï¸ Multi-node compute pools (CPU + GPU)\")\n",
        "print(\"   âš¡ Auto-scaling from 1-16 nodes\")  \n",
        "print(\"   ðŸ”— Direct integration with Snowflake ML APIs\")\n",
        "print(\"   ðŸ“Š Native distributed XGBoost support\")\n",
        "print(\"\\\\nðŸ“š Next: Run 05b_True_Distributed_Training.ipynb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## âœ… Distributed ML Setup Complete!\n",
        "\n",
        "### ðŸŽ¯ **What We Set Up (Simple & Clean):**\n",
        "\n",
        "1. **ðŸ–¥ï¸ Compute Pools Only**\n",
        "   - `ML_DISTRIBUTED_GPU_POOL` - GPU instances for intensive ML\n",
        "   - `ML_DISTRIBUTED_CPU_POOL` - CPU cluster for distributed training\n",
        "   - **Auto-scaling** from 1-16 nodes as needed\n",
        "\n",
        "2. **ðŸš€ Native Snowflake ML Integration**\n",
        "   - **No containers needed** - Snowflake ML APIs use compute pools directly\n",
        "   - **No Docker complexity** - everything works natively\n",
        "   - **Built-in distributed training** - XGBoost, scikit-learn, etc.\n",
        "\n",
        "### ðŸ“‹ **Why This Approach Works Better:**\n",
        "\n",
        "- âœ… **Simplest setup** - just compute pools\n",
        "- âœ… **Native ML APIs** - Snowflake handles distribution automatically  \n",
        "- âœ… **No container management** - focus on ML, not infrastructure\n",
        "- âœ… **Enterprise ready** - integrated with ML Registry and Feature Store\n",
        "\n",
        "### ðŸš€ **Next Step: Distributed Training**\n",
        "\n",
        "**Ready for notebook `05b_True_Distributed_Training.ipynb`!**\n",
        "\n",
        "The Snowflake ML APIs will automatically:\n",
        "- **Use the compute pools** for distributed training\n",
        "- **Scale across multiple nodes** (2-16 nodes)\n",
        "- **Handle data distribution** automatically\n",
        "- **Integrate results** back to ML Registry\n",
        "\n",
        "### ðŸ” **Verify Setup:**\n",
        "- Check **Snowflake UI > Admin > Compute Pools**\n",
        "- Look for `ML_DISTRIBUTED_CPU_POOL` and `ML_DISTRIBUTED_GPU_POOL`\n",
        "- Status should show \"ACTIVE\" or \"IDLE\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
