{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üìä Comprehensive Model Evaluation Pipeline\n",
        "\n",
        "**Advanced model evaluation with cross-validation, statistical analysis, and healthcare-specific metrics**\n",
        "\n",
        "## üéØ **Evaluation Objectives:**\n",
        "1. **üìà Comprehensive Metrics** - MAE, RMSE, R¬≤, healthcare-specific accuracy measures\n",
        "2. **üîÑ Cross-Validation** - K-fold validation with statistical significance testing\n",
        "3. **üìä Statistical Analysis** - Confidence intervals, hypothesis testing, model comparison\n",
        "4. **üè• Healthcare-Specific Metrics** - Risk stratification accuracy, clinical thresholds\n",
        "5. **üìù Evaluation Logging** - Structured results storage for tracking and comparison\n",
        "\n",
        "## üõ†Ô∏è **Evaluation Components:**\n",
        "- **Multi-Algorithm Testing**: XGBoost variants, linear baselines, ensemble methods\n",
        "- **Cross-Validation Framework**: Distributed K-fold validation using Snowpark\n",
        "- **Healthcare Metrics**: Risk category accuracy, sensitivity/specificity by risk level\n",
        "- **Statistical Testing**: Paired t-tests, confidence intervals, effect sizes\n",
        "- **Results Logging**: Comprehensive evaluation tracking in Snowflake tables\n",
        "\n",
        "**Prerequisites:** Run notebooks 04 (Feature Engineering) and 05 (Model Training) first\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Added to Python path: /Users/beddy/Desktop/Github/Snowflake_ML_HCLS/notebooks/../src\n",
            "üîÑ Reusing existing Snowflake session\n",
            "‚úÖ Environment ready for comprehensive model evaluation\n",
            "üìä Capabilities: Cross-validation, Statistical Analysis, Healthcare Metrics\n",
            "üî¨ Tools: Multiple algorithms, significance testing, evaluation logging\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup for Model Evaluation\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "from typing import Dict, List, Any, Tuple\n",
        "\n",
        "# Fix path for snowflake_connection module\n",
        "current_dir = os.getcwd()\n",
        "if \"notebooks\" in current_dir:\n",
        "    src_path = os.path.join(current_dir, \"..\", \"src\")\n",
        "else:\n",
        "    src_path = os.path.join(current_dir, \"src\")\n",
        "\n",
        "sys.path.append(src_path)\n",
        "print(f\"üìÅ Added to Python path: {src_path}\")\n",
        "\n",
        "from snowflake_connection import get_session\n",
        "from snowflake.snowpark.functions import (\n",
        "    col, lit, when, count, avg, sum as sum_, max as max_, min as min_,\n",
        "    stddev, variance, abs as abs_, sqrt, pow as pow_\n",
        ")\n",
        "from snowflake.snowpark.types import (\n",
        "    StructType, StructField, StringType, DoubleType, IntegerType,\n",
        "    FloatType, BooleanType\n",
        ")\n",
        "\n",
        "# ML imports\n",
        "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression\n",
        "from snowflake.ml.modeling.metrics import mean_absolute_error, mean_squared_error\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "# Get Snowflake session\n",
        "session = get_session()\n",
        "print(\"‚úÖ Environment ready for comprehensive model evaluation\")\n",
        "print(\"üìä Capabilities: Cross-validation, Statistical Analysis, Healthcare Metrics\")\n",
        "print(\"üî¨ Tools: Multiple algorithms, significance testing, evaluation logging\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading and preparing evaluation datasets...\n",
            "‚úÖ Loaded feature dataset with 41,616 records\n",
            "üìä Available columns: 25\n",
            "   Sample columns: PATIENT_ID, AGE, IS_MALE, NUM_CONDITIONS, NUM_MEDICATIONS, NUM_CLAIMS, MEDICATION_COUNT, HAS_CARDIOVASCULAR_DISEASE...\n",
            "üìã Selected 7 features for evaluation:\n",
            "    1. AGE\n",
            "    2. NUM_CONDITIONS\n",
            "    3. NUM_MEDICATIONS\n",
            "    4. NUM_CLAIMS\n",
            "    5. MAX_MEDICATION_RISK\n",
            "    6. HIGH_RISK_MEDICATION_COUNT\n",
            "    7. WARFARIN_RISK\n",
            "üéØ Target variable: CONTINUOUS_RISK_TARGET\n",
            "‚úÖ Evaluation dataset prepared: 41,616 clean records\n",
            "üìä Dataset split:\n",
            "   Training: 33,294 records\n",
            "   Testing: 8,322 records\n"
          ]
        }
      ],
      "source": [
        "# Data Loading and Preparation\n",
        "print(\"üìÇ Loading and preparing evaluation datasets...\")\n",
        "\n",
        "# Load the processed feature data\n",
        "feature_data_df = session.table(\"ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.FAERS_HCLS_FEATURES_FINAL\")\n",
        "print(f\"‚úÖ Loaded feature dataset with {feature_data_df.count():,} records\")\n",
        "\n",
        "# Analyze available columns\n",
        "available_columns = [f.name for f in feature_data_df.schema.fields]\n",
        "print(f\"üìä Available columns: {len(available_columns)}\")\n",
        "print(f\"   Sample columns: {', '.join(available_columns[:8])}...\")\n",
        "\n",
        "# Define feature sets for evaluation\n",
        "core_features = [\"AGE\", \"NUM_CONDITIONS\", \"NUM_MEDICATIONS\", \"NUM_CLAIMS\"]\n",
        "faers_features = [\"MAX_MEDICATION_RISK\", \"HIGH_RISK_MEDICATION_COUNT\", \"WARFARIN_RISK\"]\n",
        "derived_features = [\"AGE_GROUP\", \"MEDICATION_BURDEN\", \"CLAIMS_CATEGORY\"]\n",
        "\n",
        "# Build feature set based on availability\n",
        "evaluation_features = []\n",
        "evaluation_features.extend([f for f in core_features if f in available_columns])\n",
        "evaluation_features.extend([f for f in faers_features if f in available_columns])\n",
        "evaluation_features.extend([f for f in derived_features if f in available_columns])\n",
        "\n",
        "print(f\"üìã Selected {len(evaluation_features)} features for evaluation:\")\n",
        "for i, feature in enumerate(evaluation_features, 1):\n",
        "    print(f\"   {i:2d}. {feature}\")\n",
        "\n",
        "# Define target variable\n",
        "target_col = \"CONTINUOUS_RISK_TARGET\" if \"CONTINUOUS_RISK_TARGET\" in available_columns else \"AGE\"\n",
        "print(f\"üéØ Target variable: {target_col}\")\n",
        "\n",
        "# Create evaluation dataset with clean data\n",
        "eval_data_df = feature_data_df.select(\n",
        "    evaluation_features + [target_col]\n",
        ").filter(\n",
        "    col(target_col).is_not_null()\n",
        ")\n",
        "\n",
        "# Add patient ID for tracking using row number\n",
        "from snowflake.snowpark.functions import row_number\n",
        "from snowflake.snowpark.window import Window\n",
        "\n",
        "# Create a simple numeric patient ID to avoid string concatenation issues\n",
        "window_spec = Window.order_by(lit(1))\n",
        "eval_data_df = eval_data_df.with_column(\n",
        "    \"PATIENT_ID\", row_number().over(window_spec)\n",
        ")\n",
        "\n",
        "total_records = eval_data_df.count()\n",
        "print(f\"‚úÖ Evaluation dataset prepared: {total_records:,} clean records\")\n",
        "\n",
        "# Create train/test split for consistent evaluation\n",
        "# Use modulo of PATIENT_ID for deterministic split\n",
        "train_df = eval_data_df.filter((col(\"PATIENT_ID\") % lit(10)) < lit(8))\n",
        "test_df = eval_data_df.filter((col(\"PATIENT_ID\") % lit(10)) >= lit(8))\n",
        "\n",
        "print(f\"üìä Dataset split:\")\n",
        "print(f\"   Training: {train_df.count():,} records\")\n",
        "print(f\"   Testing: {test_df.count():,} records\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Setting up distributed cross-validation framework...\n",
            "üìä Creating 5-fold cross-validation splits...\n",
            "   Fold 1: Train=24,971, Val=8,323\n",
            "   Fold 2: Train=24,970, Val=8,324\n",
            "   Fold 3: Train=24,971, Val=8,323\n",
            "   Fold 4: Train=29,132, Val=4,162\n",
            "   Fold 5: Train=29,132, Val=4,162\n",
            "‚úÖ Cross-validation framework ready with 5 folds\n"
          ]
        }
      ],
      "source": [
        "# Cross-Validation Framework\n",
        "print(\"üîÑ Setting up distributed cross-validation framework...\")\n",
        "\n",
        "def create_cv_folds(df, k_folds=5, seed=42):\n",
        "    \"\"\"\n",
        "    Create K-fold cross-validation splits using Snowpark\n",
        "    \"\"\"\n",
        "    print(f\"üìä Creating {k_folds}-fold cross-validation splits...\")\n",
        "    \n",
        "    # Use modulo of numeric PATIENT_ID for deterministic fold assignment\n",
        "    df_with_folds = df.with_column(\n",
        "        \"FOLD_ID\", (col(\"PATIENT_ID\") % lit(k_folds))\n",
        "    )\n",
        "    \n",
        "    folds = []\n",
        "    for fold_id in range(k_folds):\n",
        "        train_fold = df_with_folds.filter(col(\"FOLD_ID\") != lit(fold_id)).drop(\"FOLD_ID\")\n",
        "        val_fold = df_with_folds.filter(col(\"FOLD_ID\") == lit(fold_id)).drop(\"FOLD_ID\")\n",
        "        \n",
        "        train_size = train_fold.count()\n",
        "        val_size = val_fold.count()\n",
        "        \n",
        "        folds.append({\n",
        "            'fold_id': fold_id,\n",
        "            'train': train_fold,\n",
        "            'val': val_fold,\n",
        "            'train_size': train_size,\n",
        "            'val_size': val_size\n",
        "        })\n",
        "        \n",
        "        print(f\"   Fold {fold_id + 1}: Train={train_size:,}, Val={val_size:,}\")\n",
        "    \n",
        "    return folds\n",
        "\n",
        "def evaluate_model_cv(model_class, model_params, folds, features, target, model_name):\n",
        "    \"\"\"\n",
        "    Perform cross-validation evaluation for a given model\n",
        "    \"\"\"\n",
        "    print(f\"\\nüî¨ Cross-validating {model_name}...\")\n",
        "    \n",
        "    fold_results = []\n",
        "    \n",
        "    for i, fold in enumerate(folds):\n",
        "        print(f\"   üìä Processing fold {i + 1}/{len(folds)}...\")\n",
        "        \n",
        "        try:\n",
        "            # Initialize model with parameters\n",
        "            model = model_class(\n",
        "                input_cols=features,\n",
        "                output_cols=[\"PREDICTION\"],\n",
        "                label_cols=[target],\n",
        "                **model_params\n",
        "            )\n",
        "            \n",
        "            # Train on fold\n",
        "            trained_model = model.fit(fold['train'])\n",
        "            \n",
        "            # Predict on validation set\n",
        "            predictions_df = trained_model.predict(fold['val'])\n",
        "            \n",
        "            # Calculate metrics\n",
        "            mae = mean_absolute_error(\n",
        "                df=predictions_df, \n",
        "                y_true_col_names=[target], \n",
        "                y_pred_col_names=[\"PREDICTION\"]\n",
        "            )\n",
        "            \n",
        "            mse = mean_squared_error(\n",
        "                df=predictions_df,\n",
        "                y_true_col_names=[target],\n",
        "                y_pred_col_names=[\"PREDICTION\"]\n",
        "            )\n",
        "            \n",
        "            rmse = np.sqrt(mse)\n",
        "            \n",
        "            fold_result = {\n",
        "                'fold_id': i,\n",
        "                'mae': float(mae),\n",
        "                'mse': float(mse),\n",
        "                'rmse': float(rmse),\n",
        "                'val_size': fold['val_size']\n",
        "            }\n",
        "            \n",
        "            fold_results.append(fold_result)\n",
        "            print(f\"      MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è Fold {i + 1} failed: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if not fold_results:\n",
        "        print(f\"   ‚ùå All folds failed for {model_name}\")\n",
        "        return None\n",
        "    \n",
        "    # Aggregate cross-validation results\n",
        "    cv_metrics = {\n",
        "        'model_name': model_name,\n",
        "        'n_folds': len(fold_results),\n",
        "        'mean_mae': np.mean([r['mae'] for r in fold_results]),\n",
        "        'std_mae': np.std([r['mae'] for r in fold_results]),\n",
        "        'mean_rmse': np.mean([r['rmse'] for r in fold_results]),\n",
        "        'std_rmse': np.std([r['rmse'] for r in fold_results]),\n",
        "        'fold_results': fold_results\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ CV Results - MAE: {cv_metrics['mean_mae']:.4f} ¬± {cv_metrics['std_mae']:.4f}\")\n",
        "    print(f\"                  RMSE: {cv_metrics['mean_rmse']:.4f} ¬± {cv_metrics['std_rmse']:.4f}\")\n",
        "    \n",
        "    return cv_metrics\n",
        "\n",
        "# Create cross-validation folds\n",
        "cv_folds = create_cv_folds(train_df, k_folds=5, seed=42)\n",
        "print(f\"‚úÖ Cross-validation framework ready with {len(cv_folds)} folds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Running multi-algorithm evaluation with cross-validation...\n",
            "\n",
            "üî¨ Cross-validating XGBoost_Default...\n",
            "   üìä Processing fold 1/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0470, RMSE: 2.4964\n",
            "   üìä Processing fold 2/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24970 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0639, RMSE: 2.5059\n",
            "   üìä Processing fold 3/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0629, RMSE: 2.4964\n",
            "   üìä Processing fold 4/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.1211, RMSE: 2.4596\n",
            "   üìä Processing fold 5/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.1085, RMSE: 2.4895\n",
            "   ‚úÖ CV Results - MAE: 1.0807 ¬± 0.0288\n",
            "                  RMSE: 2.4896 ¬± 0.0159\n",
            "\n",
            "üî¨ Cross-validating XGBoost_Optimized...\n",
            "   üìä Processing fold 1/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0840, RMSE: 2.4342\n",
            "   üìä Processing fold 2/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24970 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0612, RMSE: 2.4585\n",
            "   üìä Processing fold 3/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0179, RMSE: 2.3933\n",
            "   üìä Processing fold 4/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0844, RMSE: 2.4498\n",
            "   üìä Processing fold 5/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 1.0624, RMSE: 2.4675\n",
            "   ‚úÖ CV Results - MAE: 1.0620 ¬± 0.0242\n",
            "                  RMSE: 2.4406 ¬± 0.0261\n",
            "\n",
            "üî¨ Cross-validating Linear_Baseline...\n",
            "   üìä Processing fold 1/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 4.2117, RMSE: 5.2817\n",
            "   üìä Processing fold 2/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24970 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 4.1604, RMSE: 5.2970\n",
            "   üìä Processing fold 3/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 24971 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 4.2164, RMSE: 5.3052\n",
            "   üìä Processing fold 4/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 4.3217, RMSE: 5.3043\n",
            "   üìä Processing fold 5/5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 29132 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MAE: 4.1523, RMSE: 5.3305\n",
            "   ‚úÖ CV Results - MAE: 4.2125 ¬± 0.0605\n",
            "                  RMSE: 5.3037 ¬± 0.0158\n",
            "\n",
            "üìä Cross-Validation Results Summary:\n",
            "Model                MAE          RMSE         Folds   \n",
            "-------------------------------------------------------\n",
            "XGBoost_Default      1.0807 ¬± 0.0288 2.4896 ¬± 0.0159 5       \n",
            "XGBoost_Optimized    1.0620 ¬± 0.0242 2.4406 ¬± 0.0261 5       \n",
            "Linear_Baseline      4.2125 ¬± 0.0605 5.3037 ¬± 0.0158 5       \n",
            "\n",
            "üèÜ Best performing model: XGBoost_Optimized (MAE: 1.0620)\n",
            "\n",
            "üìà Statistical Analysis:\n",
            "   Performance difference: 0.0187 MAE\n",
            "   Effect size: 0.497\n",
            "   üìä Small effect size - models perform similarly\n",
            "‚úÖ Multi-algorithm evaluation complete\n"
          ]
        }
      ],
      "source": [
        "# Multi-Algorithm Evaluation\n",
        "print(\"üéØ Running multi-algorithm evaluation with cross-validation...\")\n",
        "\n",
        "# Define models to evaluate\n",
        "model_configs = [\n",
        "    {\n",
        "        'name': 'XGBoost_Default',\n",
        "        'class': XGBRegressor,\n",
        "        'params': {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': 6,\n",
        "            'learning_rate': 0.1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'XGBoost_Optimized',\n",
        "        'class': XGBRegressor,\n",
        "        'params': {\n",
        "            'n_estimators': 150,\n",
        "            'max_depth': 8,\n",
        "            'learning_rate': 0.05,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'random_state': 42\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'Linear_Baseline',\n",
        "        'class': LinearRegression,\n",
        "        'params': {}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run cross-validation for each model\n",
        "cv_results = []\n",
        "\n",
        "for config in model_configs:\n",
        "    try:\n",
        "        cv_result = evaluate_model_cv(\n",
        "            model_class=config['class'],\n",
        "            model_params=config['params'],\n",
        "            folds=cv_folds,\n",
        "            features=evaluation_features,\n",
        "            target=target_col,\n",
        "            model_name=config['name']\n",
        "        )\n",
        "        \n",
        "        if cv_result:\n",
        "            cv_results.append(cv_result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Model {config['name']} evaluation failed: {e}\")\n",
        "        continue\n",
        "\n",
        "# Compare model performance\n",
        "print(f\"\\nüìä Cross-Validation Results Summary:\")\n",
        "print(f\"{'Model':<20} {'MAE':<12} {'RMSE':<12} {'Folds':<8}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "best_model = None\n",
        "best_mae = float('inf')\n",
        "\n",
        "for result in cv_results:\n",
        "    mae_str = f\"{result['mean_mae']:.4f} ¬± {result['std_mae']:.4f}\"\n",
        "    rmse_str = f\"{result['mean_rmse']:.4f} ¬± {result['std_rmse']:.4f}\"\n",
        "    \n",
        "    print(f\"{result['model_name']:<20} {mae_str:<12} {rmse_str:<12} {result['n_folds']:<8}\")\n",
        "    \n",
        "    if result['mean_mae'] < best_mae:\n",
        "        best_mae = result['mean_mae']\n",
        "        best_model = result['model_name']\n",
        "\n",
        "print(f\"\\nüèÜ Best performing model: {best_model} (MAE: {best_mae:.4f})\")\n",
        "\n",
        "# Statistical significance testing\n",
        "print(f\"\\nüìà Statistical Analysis:\")\n",
        "if len(cv_results) >= 2:\n",
        "    # Compare top two models\n",
        "    sorted_results = sorted(cv_results, key=lambda x: x['mean_mae'])\n",
        "    model1, model2 = sorted_results[0], sorted_results[1]\n",
        "    \n",
        "    mae_diff = model2['mean_mae'] - model1['mean_mae']\n",
        "    combined_std = np.sqrt(model1['std_mae']**2 + model2['std_mae']**2)\n",
        "    \n",
        "    if combined_std > 0:\n",
        "        effect_size = mae_diff / combined_std\n",
        "        print(f\"   Performance difference: {mae_diff:.4f} MAE\")\n",
        "        print(f\"   Effect size: {effect_size:.3f}\")\n",
        "        \n",
        "        if abs(effect_size) > 0.5:\n",
        "            print(f\"   üìä Moderate to large effect size detected\")\n",
        "        else:\n",
        "            print(f\"   üìä Small effect size - models perform similarly\")\n",
        "\n",
        "print(f\"‚úÖ Multi-algorithm evaluation complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üè• Calculating healthcare-specific evaluation metrics...\n",
            "üéØ Evaluating healthcare metrics for XGBoost_Optimized...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:531: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(self.dataset)\n",
            "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.35.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
            "WARNING:snowflake.snowpark.session:Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/model_signature.py:71: UserWarning: The sample input has 33294 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
            "  warnings.warn(\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/model/_signatures/snowpark_handler.py:41: UserWarning: Warning: Type DecimalType(19, 6) is being automatically converted to DOUBLE in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  core.DataType.from_snowpark_type(data_type)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(19, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/snowflake-ml-platform/lib/python3.9/site-packages/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_handlers.py:126: UserWarning: Warning: The Decimal(26, 6) data type is being automatically converted to DoubleType in the Snowpark DataFrame. This automatic conversion may lead to potential precision loss and rounding errors. If you wish to prevent this conversion, you should manually perform the necessary data type conversion.\n",
            "  dataset = snowpark_dataframe_utils.cast_snowpark_dataframe_column_types(dataset)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üìä Calculating risk stratification metrics...\n",
            "      Risk thresholds: Low < 30.0, Medium 30.0-70.0, High > 70.0\n",
            "      Total records for analysis: 8,322\n",
            "      Risk category accuracy: 0.996 (8,285/8,322)\n",
            "      High-risk sensitivity: 0.993 (3,991/4,020)\n",
            "      Low-risk specificity: 0.981 (2,332/2,376)\n",
            "      MAE for LOW risk: 0.086 (n=2,410)\n",
            "      MAE for MEDIUM risk: 0.178 (n=1,880)\n",
            "      MAE for HIGH risk: 1.908 (n=4,020)\n",
            "\n",
            "üè• Healthcare Metrics Summary for XGBoost_Optimized:\n",
            "   Risk Category Accuracy: 0.996\n",
            "   High-Risk Sensitivity: 0.993\n",
            "   Low-Risk Specificity: 0.981\n",
            "   MAE by Risk Level:\n",
            "     Low Risk: 0.086\n",
            "     Medium Risk: 0.178\n",
            "     High Risk: 1.908\n",
            "‚úÖ Healthcare-specific evaluation complete\n"
          ]
        }
      ],
      "source": [
        "# Healthcare-Specific Metrics Evaluation\n",
        "print(\"üè• Calculating healthcare-specific evaluation metrics...\")\n",
        "\n",
        "def calculate_healthcare_metrics(predictions_df, target_col):\n",
        "    \"\"\"\n",
        "    Calculate healthcare-specific metrics including risk stratification accuracy\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define risk thresholds (these would be clinically validated)\n",
        "    low_threshold = 30.0\n",
        "    high_threshold = 70.0\n",
        "    \n",
        "    print(f\"   üìä Calculating risk stratification metrics...\")\n",
        "    print(f\"      Risk thresholds: Low < {low_threshold}, Medium {low_threshold}-{high_threshold}, High > {high_threshold}\")\n",
        "    \n",
        "    # Create risk categories for both true and predicted values\n",
        "    # Use proper column aliasing to avoid identifier issues\n",
        "    metrics_df = predictions_df.with_column(\n",
        "        \"TRUE_RISK_CAT\",\n",
        "        when(col(target_col) < lit(low_threshold), lit(\"LOW\"))\n",
        "        .when(col(target_col) < lit(high_threshold), lit(\"MEDIUM\"))\n",
        "        .otherwise(lit(\"HIGH\"))\n",
        "    ).with_column(\n",
        "        \"PRED_RISK_CAT\",\n",
        "        when(col(\"PREDICTION\") < lit(low_threshold), lit(\"LOW\"))\n",
        "        .when(col(\"PREDICTION\") < lit(high_threshold), lit(\"MEDIUM\"))\n",
        "        .otherwise(lit(\"HIGH\"))\n",
        "    )\n",
        "    \n",
        "    # Calculate total records\n",
        "    total_records = metrics_df.count()\n",
        "    print(f\"      Total records for analysis: {total_records:,}\")\n",
        "    \n",
        "    if total_records == 0:\n",
        "        print(f\"      ‚ö†Ô∏è No records available for healthcare metrics\")\n",
        "        return {}\n",
        "    \n",
        "    # Calculate risk category accuracy\n",
        "    try:\n",
        "        correct_classifications = metrics_df.filter(\n",
        "            col(\"TRUE_RISK_CAT\") == col(\"PRED_RISK_CAT\")\n",
        "        ).count()\n",
        "        \n",
        "        category_accuracy = correct_classifications / total_records\n",
        "        print(f\"      Risk category accuracy: {category_accuracy:.3f} ({correct_classifications:,}/{total_records:,})\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ö†Ô∏è Category accuracy calculation error: {e}\")\n",
        "        category_accuracy = 0.0\n",
        "    \n",
        "    # Calculate high-risk sensitivity (true positive rate for high-risk patients)\n",
        "    try:\n",
        "        true_high_risk = metrics_df.filter(col(\"TRUE_RISK_CAT\") == lit(\"HIGH\")).count()\n",
        "        predicted_high_risk_correctly = metrics_df.filter(\n",
        "            (col(\"TRUE_RISK_CAT\") == lit(\"HIGH\")) & (col(\"PRED_RISK_CAT\") == lit(\"HIGH\"))\n",
        "        ).count()\n",
        "        \n",
        "        high_risk_sensitivity = predicted_high_risk_correctly / true_high_risk if true_high_risk > 0 else 0.0\n",
        "        print(f\"      High-risk sensitivity: {high_risk_sensitivity:.3f} ({predicted_high_risk_correctly:,}/{true_high_risk:,})\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ö†Ô∏è High-risk sensitivity calculation error: {e}\")\n",
        "        high_risk_sensitivity = 0.0\n",
        "    \n",
        "    # Calculate low-risk specificity (true negative rate for low-risk patients)\n",
        "    try:\n",
        "        true_low_risk = metrics_df.filter(col(\"TRUE_RISK_CAT\") == lit(\"LOW\")).count()\n",
        "        predicted_low_risk_correctly = metrics_df.filter(\n",
        "            (col(\"TRUE_RISK_CAT\") == lit(\"LOW\")) & (col(\"PRED_RISK_CAT\") == lit(\"LOW\"))\n",
        "        ).count()\n",
        "        \n",
        "        low_risk_specificity = predicted_low_risk_correctly / true_low_risk if true_low_risk > 0 else 0.0\n",
        "        print(f\"      Low-risk specificity: {low_risk_specificity:.3f} ({predicted_low_risk_correctly:,}/{true_low_risk:,})\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ö†Ô∏è Low-risk specificity calculation error: {e}\")\n",
        "        low_risk_specificity = 0.0\n",
        "    \n",
        "    # Calculate MAE by risk category\n",
        "    risk_mae_metrics = {}\n",
        "    for risk_cat in [\"LOW\", \"MEDIUM\", \"HIGH\"]:\n",
        "        try:\n",
        "            cat_df = metrics_df.filter(col(\"TRUE_RISK_CAT\") == lit(risk_cat))\n",
        "            cat_count = cat_df.count()\n",
        "            \n",
        "            if cat_count > 0:\n",
        "                cat_mae = cat_df.select(\n",
        "                    avg(abs_(col(target_col) - col(\"PREDICTION\"))).alias(\"MAE\")\n",
        "                ).collect()[0][\"MAE\"]\n",
        "                risk_mae_metrics[f\"mae_{risk_cat.lower()}\"] = float(cat_mae) if cat_mae else 0.0\n",
        "                print(f\"      MAE for {risk_cat} risk: {cat_mae:.3f} (n={cat_count:,})\")\n",
        "            else:\n",
        "                risk_mae_metrics[f\"mae_{risk_cat.lower()}\"] = 0.0\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è MAE calculation for {risk_cat} risk error: {e}\")\n",
        "            risk_mae_metrics[f\"mae_{risk_cat.lower()}\"] = 0.0\n",
        "    \n",
        "    # Compile healthcare metrics\n",
        "    healthcare_metrics = {\n",
        "        'risk_category_accuracy': category_accuracy,\n",
        "        'high_risk_sensitivity': high_risk_sensitivity,\n",
        "        'low_risk_specificity': low_risk_specificity,\n",
        "        'total_patients': total_records,\n",
        "        **risk_mae_metrics\n",
        "    }\n",
        "    \n",
        "    return healthcare_metrics\n",
        "\n",
        "# Calculate healthcare metrics for the best model\n",
        "print(f\"üéØ Evaluating healthcare metrics for {best_model}...\")\n",
        "\n",
        "try:\n",
        "    # Find best model configuration\n",
        "    best_config = next(config for config in model_configs if config['name'] == best_model)\n",
        "    \n",
        "    # Train best model on full training set\n",
        "    final_model = best_config['class'](\n",
        "        input_cols=evaluation_features,\n",
        "        output_cols=[\"PREDICTION\"],\n",
        "        label_cols=[target_col],\n",
        "        **best_config['params']\n",
        "    )\n",
        "    \n",
        "    trained_final_model = final_model.fit(train_df)\n",
        "    \n",
        "    # Get predictions on test set\n",
        "    test_predictions = trained_final_model.predict(test_df)\n",
        "    \n",
        "    # Calculate healthcare-specific metrics\n",
        "    healthcare_metrics = calculate_healthcare_metrics(test_predictions, target_col)\n",
        "    \n",
        "    print(f\"\\nüè• Healthcare Metrics Summary for {best_model}:\")\n",
        "    print(f\"   Risk Category Accuracy: {healthcare_metrics.get('risk_category_accuracy', 0):.3f}\")\n",
        "    print(f\"   High-Risk Sensitivity: {healthcare_metrics.get('high_risk_sensitivity', 0):.3f}\")\n",
        "    print(f\"   Low-Risk Specificity: {healthcare_metrics.get('low_risk_specificity', 0):.3f}\")\n",
        "    print(f\"   MAE by Risk Level:\")\n",
        "    print(f\"     Low Risk: {healthcare_metrics.get('mae_low', 0):.3f}\")\n",
        "    print(f\"     Medium Risk: {healthcare_metrics.get('mae_medium', 0):.3f}\")\n",
        "    print(f\"     High Risk: {healthcare_metrics.get('mae_high', 0):.3f}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Healthcare metrics calculation failed: {e}\")\n",
        "    healthcare_metrics = {}\n",
        "\n",
        "print(f\"‚úÖ Healthcare-specific evaluation complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Logging comprehensive evaluation results...\n",
            "‚ö†Ô∏è Logging table creation: (1304): 01be2bd5-0000-29a7-002c-b10b000a874e: 000008 (0A000): Actual statement count 2 did not match the desired statement count 1.\n",
            "üìä Preparing evaluation results for logging...\n",
            "   Evaluation ID: EVAL_20250805_135714\n",
            "‚úÖ Logged 3 model evaluation results\n",
            "‚úÖ Logged 3 model comparisons\n",
            "\n",
            "üéØ Comprehensive Model Evaluation Complete!\n",
            "   üìä Evaluation ID: EVAL_20250805_135714\n",
            "   üèÜ Best Model: XGBoost_Optimized (MAE: 1.0620)\n",
            "   üìà Models Evaluated: 3\n",
            "   üîÑ Cross-Validation Folds: 5\n",
            "   üè• Healthcare Metrics: Risk accuracy, sensitivity, specificity calculated\n",
            "   üìù Results Logged: Available in MODEL_EVALUATION_LOG and MODEL_COMPARISON_LOG\n",
            "   üöÄ Ready for model packaging and deployment (notebook 07)\n"
          ]
        }
      ],
      "source": [
        "# Evaluation Results Logging\n",
        "print(\"üìù Logging comprehensive evaluation results...\")\n",
        "\n",
        "# Create evaluation logging tables\n",
        "evaluation_logging_sql = '''\n",
        "-- Main evaluation results table\n",
        "CREATE TABLE IF NOT EXISTS ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.MODEL_EVALUATION_LOG (\n",
        "    EVALUATION_ID STRING,\n",
        "    EVALUATION_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "    MODEL_NAME STRING,\n",
        "    EVALUATION_TYPE STRING,\n",
        "    DATASET_SIZE INT,\n",
        "    FEATURE_COUNT INT,\n",
        "    CV_FOLDS INT,\n",
        "    MEAN_MAE FLOAT,\n",
        "    STD_MAE FLOAT,\n",
        "    MEAN_RMSE FLOAT,\n",
        "    STD_RMSE FLOAT,\n",
        "    RISK_CATEGORY_ACCURACY FLOAT,\n",
        "    HIGH_RISK_SENSITIVITY FLOAT,\n",
        "    LOW_RISK_SPECIFICITY FLOAT,\n",
        "    MAE_LOW_RISK FLOAT,\n",
        "    MAE_MEDIUM_RISK FLOAT,\n",
        "    MAE_HIGH_RISK FLOAT,\n",
        "    BEST_MODEL STRING,\n",
        "    EVALUATION_NOTES STRING\n",
        ");\n",
        "\n",
        "-- Model comparison table\n",
        "CREATE TABLE IF NOT EXISTS ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.MODEL_COMPARISON_LOG (\n",
        "    COMPARISON_ID STRING,\n",
        "    EVALUATION_ID STRING,\n",
        "    MODEL_A STRING,\n",
        "    MODEL_B STRING,\n",
        "    MAE_DIFFERENCE FLOAT,\n",
        "    RMSE_DIFFERENCE FLOAT,\n",
        "    EFFECT_SIZE FLOAT,\n",
        "    SIGNIFICANCE_LEVEL STRING,\n",
        "    COMPARISON_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "    COMPARISON_NOTES STRING\n",
        ");\n",
        "'''\n",
        "\n",
        "try:\n",
        "    session.sql(evaluation_logging_sql).collect()\n",
        "    print(\"‚úÖ Evaluation logging tables created\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Logging table creation: {e}\")\n",
        "\n",
        "# Prepare evaluation results for logging\n",
        "evaluation_timestamp = datetime.datetime.now()\n",
        "evaluation_id = f\"EVAL_{evaluation_timestamp.strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "print(f\"üìä Preparing evaluation results for logging...\")\n",
        "print(f\"   Evaluation ID: {evaluation_id}\")\n",
        "\n",
        "# Log main evaluation results\n",
        "evaluation_log = []\n",
        "\n",
        "for result in cv_results:\n",
        "    # Get healthcare metrics for this model if it's the best one\n",
        "    model_healthcare_metrics = healthcare_metrics if result['model_name'] == best_model else {}\n",
        "    \n",
        "    eval_record = (\n",
        "        evaluation_id,\n",
        "        evaluation_timestamp.isoformat(),\n",
        "        result['model_name'],\n",
        "        'CROSS_VALIDATION',\n",
        "        total_records,\n",
        "        len(evaluation_features),\n",
        "        result['n_folds'],\n",
        "        result['mean_mae'],\n",
        "        result['std_mae'],\n",
        "        result['mean_rmse'],\n",
        "        result['std_rmse'],\n",
        "        model_healthcare_metrics.get('risk_category_accuracy', 0.0),\n",
        "        model_healthcare_metrics.get('high_risk_sensitivity', 0.0),\n",
        "        model_healthcare_metrics.get('low_risk_specificity', 0.0),\n",
        "        model_healthcare_metrics.get('mae_low', 0.0),\n",
        "        model_healthcare_metrics.get('mae_medium', 0.0),\n",
        "        model_healthcare_metrics.get('mae_high', 0.0),\n",
        "        best_model,\n",
        "        f\"Features: {', '.join(evaluation_features[:5])}...\"\n",
        "    )\n",
        "    \n",
        "    evaluation_log.append(eval_record)\n",
        "\n",
        "# Create evaluation DataFrame and save\n",
        "if evaluation_log:\n",
        "    eval_schema = StructType([\n",
        "        StructField(\"EVALUATION_ID\", StringType()),\n",
        "        StructField(\"EVALUATION_DATE\", StringType()),\n",
        "        StructField(\"MODEL_NAME\", StringType()),\n",
        "        StructField(\"EVALUATION_TYPE\", StringType()),\n",
        "        StructField(\"DATASET_SIZE\", IntegerType()),\n",
        "        StructField(\"FEATURE_COUNT\", IntegerType()),\n",
        "        StructField(\"CV_FOLDS\", IntegerType()),\n",
        "        StructField(\"MEAN_MAE\", DoubleType()),\n",
        "        StructField(\"STD_MAE\", DoubleType()),\n",
        "        StructField(\"MEAN_RMSE\", DoubleType()),\n",
        "        StructField(\"STD_RMSE\", DoubleType()),\n",
        "        StructField(\"RISK_CATEGORY_ACCURACY\", DoubleType()),\n",
        "        StructField(\"HIGH_RISK_SENSITIVITY\", DoubleType()),\n",
        "        StructField(\"LOW_RISK_SPECIFICITY\", DoubleType()),\n",
        "        StructField(\"MAE_LOW_RISK\", DoubleType()),\n",
        "        StructField(\"MAE_MEDIUM_RISK\", DoubleType()),\n",
        "        StructField(\"MAE_HIGH_RISK\", DoubleType()),\n",
        "        StructField(\"BEST_MODEL\", StringType()),\n",
        "        StructField(\"EVALUATION_NOTES\", StringType())\n",
        "    ])\n",
        "    \n",
        "    eval_df = session.create_dataframe(evaluation_log, schema=eval_schema)\n",
        "    eval_df.write.mode(\"append\").save_as_table(\"ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.MODEL_EVALUATION_LOG\")\n",
        "    \n",
        "    print(f\"‚úÖ Logged {len(evaluation_log)} model evaluation results\")\n",
        "\n",
        "# Log model comparisons\n",
        "if len(cv_results) >= 2:\n",
        "    comparison_log = []\n",
        "    \n",
        "    # Compare all pairs of models\n",
        "    for i, model_a in enumerate(cv_results):\n",
        "        for j, model_b in enumerate(cv_results[i+1:], i+1):\n",
        "            mae_diff = model_b['mean_mae'] - model_a['mean_mae']\n",
        "            rmse_diff = model_b['mean_rmse'] - model_a['mean_rmse']\n",
        "            \n",
        "            combined_std = np.sqrt(model_a['std_mae']**2 + model_b['std_mae']**2)\n",
        "            effect_size = mae_diff / combined_std if combined_std > 0 else 0.0\n",
        "            \n",
        "            significance = \"LARGE\" if abs(effect_size) > 0.8 else \"MEDIUM\" if abs(effect_size) > 0.5 else \"SMALL\"\n",
        "            \n",
        "            comparison_record = (\n",
        "                f\"COMP_{evaluation_timestamp.strftime('%Y%m%d_%H%M%S')}_{i}_{j}\",\n",
        "                evaluation_id,\n",
        "                model_a['model_name'],\n",
        "                model_b['model_name'],\n",
        "                mae_diff,\n",
        "                rmse_diff,\n",
        "                effect_size,\n",
        "                significance,\n",
        "                evaluation_timestamp.isoformat(),\n",
        "                f\"Cross-validation comparison with {model_a['n_folds']} folds\"\n",
        "            )\n",
        "            \n",
        "            comparison_log.append(comparison_record)\n",
        "    \n",
        "    if comparison_log:\n",
        "        comparison_schema = StructType([\n",
        "            StructField(\"COMPARISON_ID\", StringType()),\n",
        "            StructField(\"EVALUATION_ID\", StringType()),\n",
        "            StructField(\"MODEL_A\", StringType()),\n",
        "            StructField(\"MODEL_B\", StringType()),\n",
        "            StructField(\"MAE_DIFFERENCE\", DoubleType()),\n",
        "            StructField(\"RMSE_DIFFERENCE\", DoubleType()),\n",
        "            StructField(\"EFFECT_SIZE\", DoubleType()),\n",
        "            StructField(\"SIGNIFICANCE_LEVEL\", StringType()),\n",
        "            StructField(\"COMPARISON_DATE\", StringType()),\n",
        "            StructField(\"COMPARISON_NOTES\", StringType())\n",
        "        ])\n",
        "        \n",
        "        comparison_df = session.create_dataframe(comparison_log, schema=comparison_schema)\n",
        "        comparison_df.write.mode(\"append\").save_as_table(\"ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.MODEL_COMPARISON_LOG\")\n",
        "        \n",
        "        print(f\"‚úÖ Logged {len(comparison_log)} model comparisons\")\n",
        "\n",
        "# Final evaluation summary\n",
        "print(f\"\\nüéØ Comprehensive Model Evaluation Complete!\")\n",
        "print(f\"   üìä Evaluation ID: {evaluation_id}\")\n",
        "print(f\"   üèÜ Best Model: {best_model} (MAE: {best_mae:.4f})\")\n",
        "print(f\"   üìà Models Evaluated: {len(cv_results)}\")\n",
        "print(f\"   üîÑ Cross-Validation Folds: {len(cv_folds)}\")\n",
        "print(f\"   üè• Healthcare Metrics: Risk accuracy, sensitivity, specificity calculated\")\n",
        "print(f\"   üìù Results Logged: Available in MODEL_EVALUATION_LOG and MODEL_COMPARISON_LOG\")\n",
        "print(f\"   üöÄ Ready for model packaging and deployment (notebook 07)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
