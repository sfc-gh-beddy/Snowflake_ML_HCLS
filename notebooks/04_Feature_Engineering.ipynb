{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Feature Engineering with FAERS+HCLS Integration\n",
    "\n",
    "**Simple, focused feature engineering using integrated FDA adverse events + healthcare claims data**\n",
    "\n",
    "## Goals:\n",
    "1. **Load FAERS+HCLS integrated data** from notebook 3b\n",
    "2. **Engineer advanced risk features** for ML training\n",
    "3. **Create target variables** for adverse event prediction\n",
    "4. **Save ML-ready dataset** for training\n",
    "\n",
    "**Next Step:** Notebook 5 handles Feature Store + ML Training\n",
    "\n",
    "## Prerequisites\n",
    "- Running in Snowflake Notebooks environment\n",
    "- Previous notebooks completed (01, 02, 03, 03b)\n",
    "- FAERS+HCLS integrated dataset available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Snowflake Session for Feature Engineering\n",
    "print(\"Initializing Snowflake session for feature engineering...\")\n",
    "\n",
    "# Import Snowpark session and functions (available in Snowflake Notebooks)\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.functions import col, lit, when, count, avg, sum as sum_, max as max_, array_contains, array_to_string\n",
    "\n",
    "# Get the active Snowflake session\n",
    "session = get_active_session()\n",
    "\n",
    "print(\"SUCCESS: Snowflake session initialized for feature engineering\")\n",
    "\n",
    "# Verify context\n",
    "current_context = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        CURRENT_DATABASE() as database,\n",
    "        CURRENT_SCHEMA() as schema,\n",
    "        CURRENT_WAREHOUSE() as warehouse\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"   Database: {current_context['DATABASE']}\")\n",
    "print(f\"   Schema: {current_context['SCHEMA']}\")\n",
    "print(f\"   Warehouse: {current_context['WAREHOUSE']}\")\n",
    "print(\"SUCCESS: Environment ready for feature engineering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAERS+HCLS Integrated Data\n",
    "print(\"Loading FAERS+HCLS integrated data from notebook 3b...\")\n",
    "\n",
    "try:\n",
    "    # Load the integrated dataset from notebook 3b\n",
    "    integrated_df = session.table(\"ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.FAERS_HCLS_INTEGRATED_DATASET\")\n",
    "    print(f\"SUCCESS: Loaded FAERS+HCLS integrated data: {integrated_df.count():,} patients\")\n",
    "except Exception as e:\n",
    "    print(f\"FAILED: Error loading integrated data: {e}\")\n",
    "    print(\"Please run notebook 3b first to create the integrated dataset\")\n",
    "    raise\n",
    "\n",
    "# Show data structure\n",
    "print(f\"\\nAvailable columns: {len(integrated_df.columns)}\")\n",
    "print(f\"   - Key columns: PATIENT_ID, AGE, NUM_CONDITIONS, NUM_MEDICATIONS...\")\n",
    "print(f\"   - FAERS features: MAX_MEDICATION_RISK, HIGH_RISK_MEDICATION_COUNT...\")\n",
    "\n",
    "# Display schema to understand column types\n",
    "print(f\"\\nSchema details:\")\n",
    "for field in integrated_df.schema.fields:\n",
    "    print(f\"   - {field.name}: {field.datatype}\")\n",
    "\n",
    "# Show a few sample rows to understand the data format\n",
    "print(f\"\\nSample data:\")\n",
    "sample_data = integrated_df.limit(3).collect()\n",
    "for i, row in enumerate(sample_data):\n",
    "    print(f\"   Row {i+1}:\")\n",
    "    # Show first few columns to understand the data\n",
    "    for j, field in enumerate(integrated_df.schema.fields[:5]):  # Show first 5 columns\n",
    "        try:\n",
    "            value = row[j]\n",
    "            print(f\"      {field.name}: {value}\")\n",
    "        except:\n",
    "            print(f\"      {field.name}: <error accessing>\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Feature Engineering\n",
    "print(\"Engineering advanced features for ML training...\")\n",
    "\n",
    "# Start with the integrated data\n",
    "feature_df = integrated_df\n",
    "\n",
    "# 0. Create binary gender indicator for Feature Store\n",
    "feature_df = feature_df.with_column(\n",
    "    \"IS_MALE\",\n",
    "    when(col(\"GENDER\") == lit(\"M\"), lit(1)).otherwise(lit(0))\n",
    ")\n",
    "\n",
    "# 1. Enhanced complexity scoring\n",
    "feature_df = feature_df.with_column(\n",
    "    \"ENHANCED_COMPLEXITY_SCORE\",\n",
    "    (col(\"AGE\") / 100.0 * 10) + \n",
    "    (col(\"NUM_CONDITIONS\") * 3) + \n",
    "    (col(\"NUM_MEDICATIONS\") * 2) +\n",
    "    (col(\"MAX_MEDICATION_RISK\") * 5)\n",
    ")\n",
    "\n",
    "# 2. FAERS-enhanced risk score\n",
    "feature_df = feature_df.with_column(\n",
    "    \"FAERS_ENHANCED_RISK\",\n",
    "    col(\"MAX_MEDICATION_RISK\") * 10 + col(\"HIGH_RISK_MEDICATION_COUNT\") * 5\n",
    ")\n",
    "\n",
    "# 3. Advanced chronic disease indicators\n",
    "chronic_diseases = {\n",
    "    \"HAS_CARDIOVASCULAR_DISEASE\": [\"cardiovascular\", \"heart\", \"cardiac\", \"hypertension\"],\n",
    "    \"HAS_DIABETES\": [\"diabetes\", \"diabetic\", \"insulin\"],\n",
    "    \"HAS_KIDNEY_DISEASE\": [\"kidney\", \"renal\", \"nephritis\"],\n",
    "    \"HAS_LIVER_DISEASE\": [\"liver\", \"hepatic\", \"cirrhosis\"]\n",
    "}\n",
    "\n",
    "for disease_flag, keywords in chronic_diseases.items():\n",
    "    # Create condition for each disease based on medication arrays\n",
    "    disease_condition = lit(False)\n",
    "    for keyword in keywords:\n",
    "        # Convert array to string and then search for keyword\n",
    "        # This handles the ARRAY datatype properly\n",
    "        medications_as_string = array_to_string(col(\"CURRENT_MEDICATIONS\"), lit(','))\n",
    "        disease_condition = disease_condition | medications_as_string.contains(lit(keyword))\n",
    "    \n",
    "    feature_df = feature_df.with_column(disease_flag, disease_condition.cast(\"int\"))\n",
    "\n",
    "print(\"SUCCESS: Enhanced feature engineering complete\")\n",
    "print(f\"   Total features: {len(feature_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Target Variables\n",
    "print(\"Creating target variables for ML training...\")\n",
    "\n",
    "# 1. Continuous risk target (0-100 scale)\n",
    "feature_df = feature_df.with_column(\n",
    "    \"CONTINUOUS_RISK_TARGET\",\n",
    "    # Normalize and combine multiple risk factors\n",
    "    ((col(\"AGE\") / 100.0 * 20) + \n",
    "     (col(\"NUM_CONDITIONS\") * 4) + \n",
    "     (col(\"NUM_MEDICATIONS\") * 3) + \n",
    "     (col(\"MAX_MEDICATION_RISK\") * 15) +\n",
    "     (col(\"HIGH_RISK_MEDICATION_COUNT\") * 8))\n",
    ")\n",
    "\n",
    "# 2. High adverse event risk target (binary)\n",
    "feature_df = feature_df.with_column(\n",
    "    \"HIGH_ADVERSE_EVENT_RISK_TARGET\",\n",
    "    when(col(\"CONTINUOUS_RISK_TARGET\") > 70, lit(1)).otherwise(lit(0))\n",
    ")\n",
    "\n",
    "print(\"SUCCESS: Target variables created\")\n",
    "print(\"   - CONTINUOUS_RISK_TARGET: 0-100 continuous risk score\")\n",
    "print(\"   - HIGH_ADVERSE_EVENT_RISK_TARGET: Binary high-risk flag\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ML-Ready Dataset\n",
    "print(\"Saving ML-ready feature dataset...\")\n",
    "\n",
    "# Save the final feature dataset\n",
    "feature_df.write.mode(\"overwrite\").save_as_table(\"ADVERSE_EVENT_MONITORING.DEMO_ANALYTICS.FAERS_HCLS_FEATURES_FINAL\")\n",
    "\n",
    "# Verification\n",
    "final_count = feature_df.count()\n",
    "feature_count = len(feature_df.columns)\n",
    "\n",
    "print(f\"SUCCESS: Feature engineering complete!\")\n",
    "print(f\"   Patients: {final_count:,}\")\n",
    "print(f\"   Features: {feature_count}\")\n",
    "print(f\"   Saved as: FAERS_HCLS_FEATURES_FINAL\")\n",
    "\n",
    "print(f\"\\nReady for Feature Store setup and ML training!\")\n",
    "print(f\"   Next: Set up Feature Store in next cell\")\n",
    "print(f\"   Then: Run notebook 05_Model_Training.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Store Setup & Registration\n",
    "print(\"Setting up Snowflake Feature Store...\")\n",
    "\n",
    "try:\n",
    "    # Import native Snowflake Feature Store APIs\n",
    "    from snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n",
    "    print(\"SUCCESS: Snowflake Feature Store APIs imported\")\n",
    "    \n",
    "    # Create Feature Store with proper creation mode\n",
    "    fs = FeatureStore(\n",
    "        session=session,\n",
    "        database=\"ADVERSE_EVENT_MONITORING\",\n",
    "        name=\"ML_FEATURE_STORE\",\n",
    "        default_warehouse=\"ADVERSE_EVENT_WH\",  # Use existing warehouse\n",
    "        creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    "    )\n",
    "    print(\"SUCCESS: Feature Store created: ADVERSE_EVENT_MONITORING.ML_FEATURE_STORE\")\n",
    "    \n",
    "    # Create and register Patient Entity\n",
    "    print(\"\\nCreating Patient Entity...\")\n",
    "    patient_entity = Entity(\n",
    "        name=\"PATIENT\",\n",
    "        join_keys=[\"PATIENT_ID\"],  # Required join key\n",
    "        desc=\"Healthcare patient entity for adverse event prediction\"\n",
    "    )\n",
    "    \n",
    "    # Register the entity\n",
    "    fs.register_entity(patient_entity)\n",
    "    print(\"SUCCESS: Patient entity registered with join key: PATIENT_ID\")\n",
    "    \n",
    "    # Create Feature Views\n",
    "    print(\"\\nCreating Feature Views...\")\n",
    "    \n",
    "    # 1. Demographics Feature View\n",
    "    demographics_fv = FeatureView(\n",
    "        name=\"PATIENT_DEMOGRAPHICS\",\n",
    "        entities=[patient_entity],\n",
    "        feature_df=feature_df.select([\"PATIENT_ID\", \"AGE\", \"IS_MALE\"]),\n",
    "        desc=\"Patient demographic features\"\n",
    "    )\n",
    "    \n",
    "    # 2. FAERS Risk Feature View\n",
    "    faers_fv = FeatureView(\n",
    "        name=\"FAERS_RISK_FEATURES\", \n",
    "        entities=[patient_entity],\n",
    "        feature_df=feature_df.select([\n",
    "            \"PATIENT_ID\", \"MAX_MEDICATION_RISK\", \"HIGH_RISK_MEDICATION_COUNT\",\n",
    "            \"HAS_HIGH_RISK_INTERACTION\", \"CONTINUOUS_RISK_TARGET\"\n",
    "        ]),\n",
    "        desc=\"FAERS adverse event risk features\"\n",
    "    )\n",
    "    \n",
    "    # 3. Healthcare Utilization Feature View\n",
    "    healthcare_fv = FeatureView(\n",
    "        name=\"HEALTHCARE_UTILIZATION\",\n",
    "        entities=[patient_entity], \n",
    "        feature_df=feature_df.select([\n",
    "            \"PATIENT_ID\", \"NUM_CONDITIONS\", \"NUM_MEDICATIONS\", \"NUM_CLAIMS\",\n",
    "            \"HAS_CARDIOVASCULAR_DISEASE\", \"HAS_DIABETES\", \"HAS_KIDNEY_DISEASE\"\n",
    "        ]),\n",
    "        desc=\"Healthcare utilization and chronic disease features\"\n",
    "    )\n",
    "    \n",
    "    # Register Feature Views\n",
    "    print(\"\\nRegistering Feature Views...\")\n",
    "    \n",
    "    fs.register_feature_view(demographics_fv, version=\"1.0\", block=True)\n",
    "    print(\"   SUCCESS: PATIENT_DEMOGRAPHICS registered\")\n",
    "    \n",
    "    fs.register_feature_view(faers_fv, version=\"1.0\", block=True)\n",
    "    print(\"   SUCCESS: FAERS_RISK_FEATURES registered\")\n",
    "    \n",
    "    fs.register_feature_view(healthcare_fv, version=\"1.0\", block=True)\n",
    "    print(\"   SUCCESS: HEALTHCARE_UTILIZATION registered\")\n",
    "    \n",
    "    # Verify Feature Store setup\n",
    "    print(\"\\nVerifying Feature Store setup...\")\n",
    "    \n",
    "    # List entities\n",
    "    entities = fs.list_entities()\n",
    "    print(f\"   Entities: {entities.count()} registered\")\n",
    "    \n",
    "    # List feature views\n",
    "    feature_views = fs.list_feature_views()\n",
    "    print(f\"   Feature Views: {feature_views.count()} registered\")\n",
    "    \n",
    "    if feature_views.count() > 0:\n",
    "        print(\"   Registered Feature Views:\")\n",
    "        try:\n",
    "            # Convert to list to iterate through feature views\n",
    "            fv_list = feature_views.collect()\n",
    "            for fv in fv_list:\n",
    "                print(f\"      â€¢ {fv['NAME']}: {fv['DESC']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      (Could not list feature view details: {e})\")\n",
    "    \n",
    "    print(\"\\nFeature Store setup complete!\")\n",
    "    print(\"Location: ADVERSE_EVENT_MONITORING.ML_FEATURE_STORE\")\n",
    "    print(\"Check Snowflake UI > Data > Features to see your Feature Store objects\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"FAILED: Feature Store API not available\")\n",
    "    print(\"Requires: snowflake-ml-python v1.5.0+ and Enterprise Edition\")\n",
    "    print(\"Try: pip install snowflake-ml-python --upgrade\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"FAILED: Feature Store setup failed: {e}\")\n",
    "    print(\"Feature data still available in FAERS_HCLS_FEATURES_FINAL table\")\n",
    "    print(\"Documentation: https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/overview\")\n",
    "\n",
    "print(f\"\\nComplete! Features ready for ML training in notebook 5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Snowflake ML Feature Engineering Complete!\n",
    "\n",
    "**What we accomplished using Snowflake ML APIs:**\n",
    "- **StandardScaler**: Normalized numerical features using distributed processing\n",
    "- **OneHotEncoder**: Encoded categorical variables with proper handling\n",
    "- **Feature Engineering**: Created complexity scores and risk indicators\n",
    "- **ML-Ready Output**: Saved preprocessed data for comprehensive ML training\n",
    "\n",
    "**Snowflake ML Preprocessing Benefits:**\n",
    "- **Distributed Processing**: Scales automatically across Snowflake compute\n",
    "- **Native Integration**: Seamless with Snowpark DataFrames\n",
    "- **Production Ready**: Enterprise-grade feature preprocessing\n",
    "- **Reusable Pipelines**: Transformers can be saved and reused\n",
    "\n",
    "**Features Created:**\n",
    "- **Scaled Features**: Age, conditions, medications, claims (standardized)\n",
    "- **Categorical Encoding**: Age categories with one-hot encoding\n",
    "- **Derived Features**: Complexity score, comorbidity flags, polypharmacy indicators\n",
    "- **Target Variable**: Adverse event indicator\n",
    "\n",
    "**Next Steps:**\n",
    "1. **Run Notebook 5**: Comprehensive ML workflow with Feature Store\n",
    "2. **Model Training**: Unsupervised + supervised learning with distributed training\n",
    "3. **Model Registry**: Log all models with metadata and lineage\n",
    "4. **ML Observability**: Set up native monitoring in notebook 7\n",
    "\n",
    "Ready for the complete Snowflake ML platform workflow!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
