{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# \ud83e\udde0 Snowflake ML Platform: Unsupervised Machine Learning\n",
    "\n",
    "This notebook demonstrates unsupervised machine learning capabilities for healthcare analytics, including patient segmentation, anomaly detection, and feature discovery.\n",
    "\n",
    "## \ud83c\udfaf What We're Building\n",
    "- **Patient Segmentation**: K-Means clustering for risk stratification\n",
    "- **Anomaly Detection**: Isolation Forest for unusual patient patterns\n",
    "- **Feature Discovery**: PCA for dimensionality reduction and insights\n",
    "- **Clinical Insights**: Interpretable clusters for healthcare decisions\n",
    "\n",
    "## \ud83d\udd2c Unsupervised ML Applications in Healthcare\n",
    "- **Patient Stratification**: Group patients by similar risk profiles\n",
    "- **Fraud Detection**: Identify unusual billing or care patterns\n",
    "- **Resource Planning**: Optimize staffing and capacity based on patient clusters\n",
    "- **Drug Discovery**: Find patient subgroups for clinical trials\n",
    "- **Quality Improvement**: Detect care pattern anomalies\n",
    "\n",
    "## \ud83d\ude80 Advanced Analytics\n",
    "```\n",
    "Feature Store \u2192 Unsupervised ML \u2192 Clinical Insights\n",
    "     \u2193              \u2193                    \u2193\n",
    "Historical      Clustering         Patient Segments\n",
    "Features        Anomaly Det.       Unusual Patterns\n",
    "                Dimensionality     Hidden Insights\n",
    "```\n",
    "\n",
    "## \ud83d\udca1 Business Value\n",
    "- **Personalized Medicine**: Tailored treatments for patient segments\n",
    "- **Operational Efficiency**: Resource allocation based on patient clusters\n",
    "- **Risk Management**: Early detection of unusual patterns\n",
    "- **Research Acceleration**: Discovery of patient subpopulations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for unsupervised machine learning\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, lit, avg, count, stddev, min, max\n",
    "from snowflake.ml.modeling.cluster import KMeans\n",
    "from snowflake.ml.modeling.ensemble import IsolationForest\n",
    "from snowflake.ml.modeling.decomposition import PCA\n",
    "from snowflake.ml.modeling.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "print(\"\ud83e\udde0 Unsupervised ML Libraries Loaded!\")\n",
    "print(\"\ud83d\udd2c Ready for patient segmentation and anomaly detection\")\n",
    "\n",
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context for unsupervised ML operations\n",
    "session.use_database(\"ADVERSE_EVENT_MONITORING\")\n",
    "session.use_warehouse(\"ADVERSE_EVENT_WH\")\n",
    "\n",
    "print(\"\u2705 Session configured for unsupervised ML\")\n",
    "print(f\"\ud83d\udccd Database: {session.get_current_database()}\")\n",
    "print(f\"\ud83d\udccd Warehouse: {session.get_current_warehouse()}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udcca Loading Healthcare Data from Feature Store...\")\n",
    "\n",
    "# Load features from the feature store (offline store for historical analysis)\n",
    "session.use_schema(\"FEATURE_STORE\")\n",
    "\n",
    "try:\n",
    "    # Load offline feature store data\n",
    "    feature_data = session.table(\"OFFLINE_FEATURE_STORE\")\n",
    "    patient_count = feature_data.count()\n",
    "    \n",
    "    print(f\"\u2705 Loaded feature store data: {patient_count} patients\")\n",
    "    \n",
    "    # Select features for unsupervised learning (exclude target variables)\n",
    "    ml_features = [\n",
    "        \"patient_age\",\n",
    "        \"total_claim_amount_sum\", \n",
    "        \"num_claims\",\n",
    "        \"avg_claim_amount\",\n",
    "        \"claims_last_30d\",\n",
    "        \"claims_last_90d\",\n",
    "        \"num_conditions\",\n",
    "        \"num_medications\", \n",
    "        \"chronic_conditions_count\",\n",
    "        \"comorbidity_score\",\n",
    "        \"medication_complexity_score\",\n",
    "        \"healthcare_utilization_score\"\n",
    "    ]\n",
    "    \n",
    "    # Prepare data for unsupervised learning\n",
    "    unsupervised_data = feature_data.select(\n",
    "        col(\"entity_id\").alias(\"patient_id\"),\n",
    "        *[col(feature) for feature in ml_features]\n",
    "    ).filter(\n",
    "        # Remove any rows with null values for clean clustering\n",
    "        col(\"patient_age\").isNotNull() & \n",
    "        col(\"total_claim_amount_sum\").isNotNull() &\n",
    "        col(\"num_conditions\").isNotNull()\n",
    "    )\n",
    "    \n",
    "    clean_count = unsupervised_data.count()\n",
    "    print(f\"\u2705 Prepared clean dataset: {clean_count} patients with {len(ml_features)} features\")\n",
    "    \n",
    "    # Show data statistics\n",
    "    print(f\"\\n\ud83d\udcc8 Feature Statistics:\")\n",
    "    stats = unsupervised_data.select(\n",
    "        avg(\"patient_age\").alias(\"avg_age\"),\n",
    "        avg(\"total_claim_amount_sum\").alias(\"avg_claims\"),\n",
    "        avg(\"num_conditions\").alias(\"avg_conditions\"),\n",
    "        avg(\"comorbidity_score\").alias(\"avg_comorbidity\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"   \u2022 Average Age: {stats['AVG_AGE']:.1f} years\")\n",
    "    print(f\"   \u2022 Average Claims: ${stats['AVG_CLAIMS']:,.0f}\")\n",
    "    print(f\"   \u2022 Average Conditions: {stats['AVG_CONDITIONS']:.1f}\")\n",
    "    print(f\"   \u2022 Average Comorbidity Score: {stats['AVG_COMORBIDITY']:.2f}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\n\ud83d\udcc4 Sample Data for Unsupervised Learning:\")\n",
    "    sample_cols = [\"patient_id\", \"patient_age\", \"num_conditions\", \"comorbidity_score\", \"healthcare_utilization_score\"]\n",
    "    unsupervised_data.select(*sample_cols).limit(5).show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading feature store data: {e}\")\n",
    "    print(\"\ud83d\udca1 Make sure you've run the 09_Feature_Store_Setup notebook first\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udfaf Patient Segmentation with K-Means Clustering...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, scale the features for better clustering performance\n",
    "print(\"\u2699\ufe0f Scaling features for optimal clustering...\")\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler(\n",
    "    input_cols=ml_features,\n",
    "    output_cols=[f\"{feature}_SCALED\" for feature in ml_features]\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit(unsupervised_data).transform(unsupervised_data)\n",
    "scaled_features = [f\"{feature}_SCALED\" for feature in ml_features]\n",
    "\n",
    "print(f\"\u2705 Features scaled successfully\")\n",
    "\n",
    "# K-Means Clustering with optimal number of clusters for healthcare segmentation\n",
    "print(f\"\\n\ud83c\udfaf Training K-Means clustering model...\")\n",
    "\n",
    "# Initialize K-Means with 4 clusters (common healthcare risk stratification)\n",
    "kmeans = KMeans(\n",
    "    n_clusters=4,              # 4 risk segments: Low, Medium, High, Critical\n",
    "    input_cols=scaled_features,\n",
    "    output_cols=[\"CLUSTER_ID\"],\n",
    "    random_state=42,\n",
    "    max_iter=100\n",
    ")\n",
    "\n",
    "# Train the clustering model\n",
    "try:\n",
    "    fitted_kmeans = kmeans.fit(scaled_data)\n",
    "    print(f\"\u2705 K-Means clustering trained successfully\")\n",
    "    \n",
    "    # Apply clustering to get patient segments\n",
    "    clustered_data = fitted_kmeans.predict(scaled_data)\n",
    "    \n",
    "    print(f\"\ud83c\udf89 Patient segmentation completed!\")\n",
    "    \n",
    "    # Analyze cluster characteristics\n",
    "    cluster_analysis = clustered_data.group_by(\"CLUSTER_ID\").agg(\n",
    "        count(\"patient_id\").alias(\"patient_count\"),\n",
    "        avg(\"patient_age\").alias(\"avg_age\"),\n",
    "        avg(\"total_claim_amount_sum\").alias(\"avg_claims\"),\n",
    "        avg(\"num_conditions\").alias(\"avg_conditions\"),\n",
    "        avg(\"comorbidity_score\").alias(\"avg_comorbidity\"),\n",
    "        avg(\"healthcare_utilization_score\").alias(\"avg_utilization\")\n",
    "    ).order_by(\"CLUSTER_ID\")\n",
    "    \n",
    "    cluster_results = cluster_analysis.collect()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Patient Cluster Analysis:\")\n",
    "    print(f\"=\" * 80)\n",
    "    \n",
    "    # Define cluster interpretations based on characteristics\n",
    "    cluster_names = {\n",
    "        0: \"\ud83d\udfe2 LOW RISK\",\n",
    "        1: \"\ud83d\udfe1 MEDIUM RISK\", \n",
    "        2: \"\ud83d\udfe0 HIGH RISK\",\n",
    "        3: \"\ud83d\udd34 CRITICAL RISK\"\n",
    "    }\n",
    "    \n",
    "    total_patients = sum(row[\"PATIENT_COUNT\"] for row in cluster_results)\n",
    "    \n",
    "    for cluster in cluster_results:\n",
    "        cluster_id = cluster[\"CLUSTER_ID\"]\n",
    "        patient_count = cluster[\"PATIENT_COUNT\"]\n",
    "        percentage = (patient_count / total_patients) * 100\n",
    "        \n",
    "        # Determine cluster interpretation\n",
    "        comorbidity = cluster[\"AVG_COMORBIDITY\"]\n",
    "        utilization = cluster[\"AVG_UTILIZATION\"]\n",
    "        \n",
    "        if comorbidity <= 1.0 and utilization <= 2.0:\n",
    "            risk_level = \"\ud83d\udfe2 LOW RISK\"\n",
    "            interpretation = \"Healthy patients with minimal healthcare needs\"\n",
    "        elif comorbidity <= 2.0 and utilization <= 4.0:\n",
    "            risk_level = \"\ud83d\udfe1 MEDIUM RISK\"\n",
    "            interpretation = \"Moderate complexity patients requiring regular monitoring\"\n",
    "        elif comorbidity <= 3.0 or utilization <= 6.0:\n",
    "            risk_level = \"\ud83d\udfe0 HIGH RISK\" \n",
    "            interpretation = \"Complex patients with multiple conditions\"\n",
    "        else:\n",
    "            risk_level = \"\ud83d\udd34 CRITICAL RISK\"\n",
    "            interpretation = \"Very high complexity patients requiring intensive management\"\n",
    "        \n",
    "        print(f\"\\nCluster {cluster_id}: {risk_level}\")\n",
    "        print(f\"   \ud83d\udcca Patients: {patient_count} ({percentage:.1f}%)\")\n",
    "        print(f\"   \ud83d\udc64 Avg Age: {cluster['AVG_AGE']:.1f} years\")\n",
    "        print(f\"   \ud83d\udcb0 Avg Claims: ${cluster['AVG_CLAIMS']:,.0f}\")\n",
    "        print(f\"   \ud83c\udfe5 Avg Conditions: {cluster['AVG_CONDITIONS']:.1f}\")\n",
    "        print(f\"   \ud83d\udcc8 Comorbidity Score: {cluster['AVG_COMORBIDITY']:.2f}\")\n",
    "        print(f\"   \u26a1 Utilization Score: {cluster['AVG_UTILIZATION']:.2f}\")\n",
    "        print(f\"   \ud83d\udca1 Profile: {interpretation}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error in K-Means clustering: {e}\")\n",
    "    # Create a simple fallback clustering for demo\n",
    "    clustered_data = unsupervised_data.with_column(\n",
    "        \"CLUSTER_ID\", \n",
    "        (col(\"comorbidity_score\")).cast(\"int\")\n",
    "    )\n",
    "    print(\"\ud83d\udcdd Using simplified clustering based on comorbidity score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83d\udea8 Anomaly Detection with Isolation Forest...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use Isolation Forest to detect unusual patient patterns\n",
    "print(\"\ud83d\udd0d Training Isolation Forest for anomaly detection...\")\n",
    "\n",
    "# Initialize Isolation Forest\n",
    "isolation_forest = IsolationForest(\n",
    "    input_cols=scaled_features,\n",
    "    output_cols=[\"ANOMALY_SCORE\"],\n",
    "    contamination=0.1,  # Expect ~10% of patients to be anomalies\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Train the anomaly detection model\n",
    "    fitted_isolation_forest = isolation_forest.fit(scaled_data)\n",
    "    print(f\"\u2705 Isolation Forest trained successfully\")\n",
    "    \n",
    "    # Detect anomalies\n",
    "    anomaly_data = fitted_isolation_forest.predict(scaled_data)\n",
    "    \n",
    "    print(f\"\ud83c\udf89 Anomaly detection completed!\")\n",
    "    \n",
    "    # Analyze anomalies\n",
    "    # Note: Snowpark ML IsolationForest returns anomaly scores\n",
    "    # Negative scores typically indicate anomalies\n",
    "    \n",
    "    # Add anomaly flag based on score threshold\n",
    "    anomaly_results = anomaly_data.with_column(\n",
    "        \"IS_ANOMALY\",\n",
    "        col(\"ANOMALY_SCORE\") < -0.1  # Threshold for anomaly classification\n",
    "    )\n",
    "    \n",
    "    # Count anomalies\n",
    "    anomaly_summary = anomaly_results.group_by(\"IS_ANOMALY\").agg(\n",
    "        count(\"patient_id\").alias(\"patient_count\")\n",
    "    ).collect()\n",
    "    \n",
    "    total_patients = sum(row[\"PATIENT_COUNT\"] for row in anomaly_summary)\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd0d Anomaly Detection Results:\")\n",
    "    for row in anomaly_summary:\n",
    "        is_anomaly = row[\"IS_ANOMALY\"]\n",
    "        count = row[\"PATIENT_COUNT\"]\n",
    "        percentage = (count / total_patients) * 100\n",
    "        \n",
    "        if is_anomaly:\n",
    "            print(f\"   \ud83d\udea8 Anomalous Patients: {count} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   \u2705 Normal Patients: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Analyze characteristics of anomalous patients\n",
    "    anomaly_characteristics = anomaly_results.filter(col(\"IS_ANOMALY\") == True).agg(\n",
    "        count(\"patient_id\").alias(\"anomaly_count\"),\n",
    "        avg(\"patient_age\").alias(\"avg_age\"),\n",
    "        avg(\"total_claim_amount_sum\").alias(\"avg_claims\"),\n",
    "        avg(\"num_conditions\").alias(\"avg_conditions\"),\n",
    "        avg(\"comorbidity_score\").alias(\"avg_comorbidity\"),\n",
    "        avg(\"healthcare_utilization_score\").alias(\"avg_utilization\"),\n",
    "        min(\"ANOMALY_SCORE\").alias(\"min_anomaly_score\"),\n",
    "        max(\"ANOMALY_SCORE\").alias(\"max_anomaly_score\")\n",
    "    ).collect()\n",
    "    \n",
    "    if anomaly_characteristics and anomaly_characteristics[0][\"ANOMALY_COUNT\"] > 0:\n",
    "        anomaly_stats = anomaly_characteristics[0]\n",
    "        \n",
    "        print(f\"\\n\ud83d\udd0d Anomalous Patient Characteristics:\")\n",
    "        print(f\"   \ud83d\udc64 Average Age: {anomaly_stats['AVG_AGE']:.1f} years\")\n",
    "        print(f\"   \ud83d\udcb0 Average Claims: ${anomaly_stats['AVG_CLAIMS']:,.0f}\")\n",
    "        print(f\"   \ud83c\udfe5 Average Conditions: {anomaly_stats['AVG_CONDITIONS']:.1f}\")\n",
    "        print(f\"   \ud83d\udcc8 Average Comorbidity: {anomaly_stats['AVG_COMORBIDITY']:.2f}\")\n",
    "        print(f\"   \u26a1 Average Utilization: {anomaly_stats['AVG_UTILIZATION']:.2f}\")\n",
    "        print(f\"   \ud83d\udcca Anomaly Score Range: {anomaly_stats['MIN_ANOMALY_SCORE']:.3f} to {anomaly_stats['MAX_ANOMALY_SCORE']:.3f}\")\n",
    "        \n",
    "        # Show specific anomalous patients\n",
    "        print(f\"\\n\ud83d\udd0d Sample Anomalous Patients:\")\n",
    "        anomalous_patients = anomaly_results.filter(col(\"IS_ANOMALY\") == True).select(\n",
    "            \"patient_id\", \"patient_age\", \"total_claim_amount_sum\", \"num_conditions\", \n",
    "            \"comorbidity_score\", \"ANOMALY_SCORE\"\n",
    "        ).limit(3)\n",
    "        anomalous_patients.show()\n",
    "        \n",
    "        # Clinical interpretation of anomalies\n",
    "        print(f\"\\n\ud83d\udca1 Clinical Interpretation of Anomalies:\")\n",
    "        print(f\"   \u2022 Unusual patterns may indicate:\")\n",
    "        print(f\"     - Billing fraud or coding errors\")\n",
    "        print(f\"     - Rare disease conditions\") \n",
    "        print(f\"     - Exceptional treatment responses\")\n",
    "        print(f\"     - Data quality issues requiring investigation\")\n",
    "        print(f\"   \u2022 Recommend: Manual review by clinical experts\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"   \u2139\ufe0f No significant anomalies detected in current dataset\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error in anomaly detection: {e}\")\n",
    "    print(\"\ud83d\udcdd Continuing with simplified anomaly detection...\")\n",
    "    \n",
    "    # Simple fallback: flag patients with extreme values\n",
    "    anomaly_results = scaled_data.with_column(\n",
    "        \"IS_ANOMALY\",\n",
    "        (col(\"total_claim_amount_sum\") > 50000) | (col(\"num_conditions\") > 10)\n",
    "    ).with_column(\n",
    "        \"ANOMALY_SCORE\",\n",
    "        lit(-0.5)  # Dummy score for fallback\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83d\udd0d Feature Discovery with Principal Component Analysis (PCA)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use PCA to discover hidden patterns and reduce dimensionality\n",
    "print(\"\ud83d\udcca Training PCA for dimensionality reduction and feature discovery...\")\n",
    "\n",
    "# Initialize PCA with 4 components (matching our cluster count)\n",
    "pca = PCA(\n",
    "    input_cols=scaled_features,\n",
    "    output_cols=[\"PC1\", \"PC2\", \"PC3\", \"PC4\"],\n",
    "    n_components=4\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Train PCA\n",
    "    fitted_pca = pca.fit(scaled_data)\n",
    "    print(f\"\u2705 PCA trained successfully\")\n",
    "    \n",
    "    # Transform data to principal components\n",
    "    pca_data = fitted_pca.transform(scaled_data)\n",
    "    \n",
    "    print(f\"\ud83c\udf89 Dimensionality reduction completed!\")\n",
    "    print(f\"   \ud83d\udcc9 Reduced {len(ml_features)} features to 4 principal components\")\n",
    "    \n",
    "    # Analyze principal component characteristics\n",
    "    pc_stats = pca_data.select(\n",
    "        avg(\"PC1\").alias(\"avg_pc1\"),\n",
    "        stddev(\"PC1\").alias(\"std_pc1\"),\n",
    "        avg(\"PC2\").alias(\"avg_pc2\"),\n",
    "        stddev(\"PC2\").alias(\"std_pc2\"),\n",
    "        avg(\"PC3\").alias(\"avg_pc3\"),\n",
    "        stddev(\"PC3\").alias(\"std_pc3\"),\n",
    "        avg(\"PC4\").alias(\"avg_pc4\"),\n",
    "        stddev(\"PC4\").alias(\"std_pc4\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Principal Component Statistics:\")\n",
    "    for i in range(1, 5):\n",
    "        avg_key = f\"AVG_PC{i}\"\n",
    "        std_key = f\"STD_PC{i}\"\n",
    "        print(f\"   PC{i}: \u03bc={pc_stats[avg_key]:.3f}, \u03c3={pc_stats[std_key]:.3f}\")\n",
    "    \n",
    "    # Interpret principal components based on healthcare context\n",
    "    print(f\"\\n\ud83d\udca1 Healthcare Interpretation of Principal Components:\")\n",
    "    print(f\"   \ud83d\udd2c PC1: Likely represents 'Disease Burden' (conditions + comorbidity)\")\n",
    "    print(f\"   \ud83d\udcb0 PC2: Likely represents 'Healthcare Utilization' (claims + costs)\")\n",
    "    print(f\"   \ud83d\udc64 PC3: Likely represents 'Demographics' (age + complexity)\")\n",
    "    print(f\"   \u26a1 PC4: Likely represents 'Acute Care Needs' (recent utilization)\")\n",
    "    \n",
    "    # Show sample transformed data\n",
    "    print(f\"\\n\ud83d\udcc4 Sample PCA-Transformed Data:\")\n",
    "    pca_sample = pca_data.select(\"patient_id\", \"PC1\", \"PC2\", \"PC3\", \"PC4\").limit(5)\n",
    "    pca_sample.show()\n",
    "    \n",
    "    # Create comprehensive dataset with all unsupervised insights\n",
    "    print(f\"\\n\ud83d\udd17 Combining All Unsupervised ML Results...\")\n",
    "    \n",
    "    # Combine clustering, anomaly detection, and PCA results\n",
    "    comprehensive_results = clustered_data.join(\n",
    "        anomaly_results.select(\"patient_id\", \"IS_ANOMALY\", \"ANOMALY_SCORE\"),\n",
    "        \"patient_id\",\n",
    "        \"inner\"\n",
    "    ).join(\n",
    "        pca_data.select(\"patient_id\", \"PC1\", \"PC2\", \"PC3\", \"PC4\"),\n",
    "        \"patient_id\", \n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\u2705 Comprehensive unsupervised ML dataset created\")\n",
    "    \n",
    "    # Show sample of comprehensive results\n",
    "    print(f\"\\n\ud83d\udcc4 Sample Comprehensive Results:\")\n",
    "    comprehensive_sample = comprehensive_results.select(\n",
    "        \"patient_id\", \"CLUSTER_ID\", \"IS_ANOMALY\", \"PC1\", \"PC2\", \n",
    "        \"comorbidity_score\", \"healthcare_utilization_score\"\n",
    "    ).limit(5)\n",
    "    comprehensive_sample.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error in PCA analysis: {e}\")\n",
    "    print(\"\ud83d\udcdd Continuing without PCA transformation...\")\n",
    "    \n",
    "    # Simple fallback: use original scaled features as \"components\"\n",
    "    pca_data = scaled_data.select(\n",
    "        \"patient_id\",\n",
    "        col(scaled_features[0]).alias(\"PC1\"),\n",
    "        col(scaled_features[1]).alias(\"PC2\"), \n",
    "        col(scaled_features[2]).alias(\"PC3\"),\n",
    "        col(scaled_features[3]).alias(\"PC4\")\n",
    "    )\n",
    "    \n",
    "    comprehensive_results = clustered_data.join(\n",
    "        anomaly_results.select(\"patient_id\", \"IS_ANOMALY\", \"ANOMALY_SCORE\"),\n",
    "        \"patient_id\",\n",
    "        \"inner\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83d\udcbe Saving Unsupervised ML Results to Feature Store...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save comprehensive unsupervised ML results\n",
    "session.use_schema(\"FEATURE_STORE\")\n",
    "\n",
    "try:\n",
    "    # Create table for unsupervised ML insights\n",
    "    session.sql(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS UNSUPERVISED_ML_INSIGHTS (\n",
    "            patient_id VARCHAR(50),\n",
    "            cluster_id INTEGER,\n",
    "            cluster_risk_level VARCHAR(20),\n",
    "            is_anomaly BOOLEAN,\n",
    "            anomaly_score FLOAT,\n",
    "            pc1 FLOAT,\n",
    "            pc2 FLOAT,\n",
    "            pc3 FLOAT,\n",
    "            pc4 FLOAT,\n",
    "            patient_age INTEGER,\n",
    "            comorbidity_score FLOAT,\n",
    "            healthcare_utilization_score FLOAT,\n",
    "            analysis_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),\n",
    "            PRIMARY KEY (patient_id, analysis_date)\n",
    "        )\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Prepare data for saving with risk level interpretation\n",
    "    save_data = comprehensive_results.with_column(\n",
    "        \"cluster_risk_level\",\n",
    "        when(col(\"CLUSTER_ID\") == 0, \"LOW\")\n",
    "        .when(col(\"CLUSTER_ID\") == 1, \"MEDIUM\")\n",
    "        .when(col(\"CLUSTER_ID\") == 2, \"HIGH\")\n",
    "        .otherwise(\"CRITICAL\")\n",
    "    ).with_column(\n",
    "        \"analysis_date\",\n",
    "        lit(datetime.datetime.now())\n",
    "    ).select(\n",
    "        \"patient_id\",\n",
    "        \"CLUSTER_ID\",\n",
    "        \"cluster_risk_level\", \n",
    "        \"IS_ANOMALY\",\n",
    "        \"ANOMALY_SCORE\",\n",
    "        \"PC1\", \"PC2\", \"PC3\", \"PC4\",\n",
    "        \"patient_age\",\n",
    "        \"comorbidity_score\",\n",
    "        \"healthcare_utilization_score\",\n",
    "        \"analysis_date\"\n",
    "    )\n",
    "    \n",
    "    # Save to table\n",
    "    save_data.write.mode(\"overwrite\").save_as_table(\"UNSUPERVISED_ML_INSIGHTS\")\n",
    "    \n",
    "    saved_count = session.table(\"UNSUPERVISED_ML_INSIGHTS\").count()\n",
    "    print(f\"\u2705 Saved {saved_count} patient insights to UNSUPERVISED_ML_INSIGHTS\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error saving insights: {e}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Clinical and Business Insights from Unsupervised ML...\")\n",
    "print(f\"=\" * 60)\n",
    "\n",
    "# Generate actionable insights\n",
    "try:\n",
    "    # Cross-analysis: Clusters vs Anomalies\n",
    "    cluster_anomaly_analysis = comprehensive_results.group_by(\"CLUSTER_ID\").agg(\n",
    "        count(\"patient_id\").alias(\"total_patients\"),\n",
    "        avg(col(\"IS_ANOMALY\").cast(\"int\")).alias(\"anomaly_rate\"),\n",
    "        avg(\"comorbidity_score\").alias(\"avg_comorbidity\")\n",
    "    ).collect()\n",
    "    \n",
    "    print(f\"\ud83c\udfaf Patient Stratification Insights:\")\n",
    "    for cluster in cluster_anomaly_analysis:\n",
    "        cluster_id = cluster[\"CLUSTER_ID\"]\n",
    "        total = cluster[\"TOTAL_PATIENTS\"]\n",
    "        anomaly_rate = cluster[\"ANOMALY_RATE\"] * 100\n",
    "        comorbidity = cluster[\"AVG_COMORBIDITY\"]\n",
    "        \n",
    "        risk_level = [\"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\"][min(cluster_id, 3)]\n",
    "        \n",
    "        print(f\"\\n   \ud83d\udcca {risk_level} RISK CLUSTER {cluster_id}:\")\n",
    "        print(f\"      \ud83d\udc65 Patients: {total}\")\n",
    "        print(f\"      \ud83d\udea8 Anomaly Rate: {anomaly_rate:.1f}%\")\n",
    "        print(f\"      \ud83d\udcc8 Comorbidity: {comorbidity:.2f}\")\n",
    "        \n",
    "        # Clinical recommendations\n",
    "        if risk_level == \"LOW\":\n",
    "            print(f\"      \ud83d\udca1 Strategy: Preventive care, wellness programs\")\n",
    "        elif risk_level == \"MEDIUM\":\n",
    "            print(f\"      \ud83d\udca1 Strategy: Regular monitoring, chronic disease management\")\n",
    "        elif risk_level == \"HIGH\":\n",
    "            print(f\"      \ud83d\udca1 Strategy: Care coordination, specialist referrals\")\n",
    "        else:  # CRITICAL\n",
    "            print(f\"      \ud83d\udca1 Strategy: Intensive management, frequent monitoring\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcb0 Healthcare Economics Impact:\")\n",
    "    \n",
    "    # Calculate potential cost savings from targeted interventions\n",
    "    total_patients = sum(cluster[\"TOTAL_PATIENTS\"] for cluster in cluster_anomaly_analysis)\n",
    "    \n",
    "    # Estimate cost savings (healthcare industry benchmarks)\n",
    "    preventive_care_savings = 0.15  # 15% savings for low-risk patients\n",
    "    chronic_care_savings = 0.25     # 25% savings for medium-risk patients  \n",
    "    complex_care_savings = 0.35     # 35% savings for high/critical-risk patients\n",
    "    \n",
    "    print(f\"   \ud83d\udcca Population Analysis ({total_patients} patients):\")\n",
    "    \n",
    "    estimated_total_cost = 0\n",
    "    estimated_savings = 0\n",
    "    \n",
    "    for cluster in cluster_anomaly_analysis:\n",
    "        cluster_id = cluster[\"CLUSTER_ID\"]\n",
    "        total = cluster[\"TOTAL_PATIENTS\"]\n",
    "        percentage = (total / total_patients) * 100\n",
    "        \n",
    "        # Estimate average cost per cluster (simplified model)\n",
    "        if cluster_id == 0:  # Low risk\n",
    "            avg_cost = 2000\n",
    "            savings_rate = preventive_care_savings\n",
    "        elif cluster_id == 1:  # Medium risk\n",
    "            avg_cost = 8000\n",
    "            savings_rate = chronic_care_savings\n",
    "        elif cluster_id == 2:  # High risk\n",
    "            avg_cost = 20000\n",
    "            savings_rate = complex_care_savings\n",
    "        else:  # Critical risk\n",
    "            avg_cost = 50000\n",
    "            savings_rate = complex_care_savings\n",
    "        \n",
    "        cluster_cost = total * avg_cost\n",
    "        cluster_savings = cluster_cost * savings_rate\n",
    "        \n",
    "        estimated_total_cost += cluster_cost\n",
    "        estimated_savings += cluster_savings\n",
    "        \n",
    "        risk_level = [\"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\"][min(cluster_id, 3)]\n",
    "        print(f\"      {risk_level}: {total} patients ({percentage:.1f}%) - ${cluster_savings:,.0f} potential savings\")\n",
    "    \n",
    "    roi_percentage = (estimated_savings / estimated_total_cost) * 100\n",
    "    \n",
    "    print(f\"\\n   \ud83d\udca1 Economic Impact Summary:\")\n",
    "    print(f\"      \ud83d\udcca Total Healthcare Cost: ${estimated_total_cost:,.0f}\")\n",
    "    print(f\"      \ud83d\udcb0 Potential Annual Savings: ${estimated_savings:,.0f}\")\n",
    "    print(f\"      \ud83d\udcc8 ROI from ML Segmentation: {roi_percentage:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfe5 Operational Recommendations:\")\n",
    "    print(f\"   \u2022 \ud83c\udfaf Implement personalized care pathways by risk segment\")\n",
    "    print(f\"   \u2022 \ud83d\udea8 Set up automated alerts for anomalous patients\")\n",
    "    print(f\"   \u2022 \ud83d\udcca Use clusters for resource planning and staffing\")\n",
    "    print(f\"   \u2022 \ud83d\udd0d Investigate anomalies for fraud prevention\")\n",
    "    print(f\"   \u2022 \ud83d\udcc8 Track cluster migration to measure intervention success\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error generating insights: {e}\")\n",
    "    print(f\"\ud83d\udca1 Basic segmentation completed - manual analysis recommended\")\n",
    "\n",
    "print(f\"\\n\u2705 Unsupervised ML Analysis Complete!\")\n",
    "print(f\"\ud83c\udfaf Key outputs: Patient clusters, anomaly detection, feature discovery\")\n",
    "print(f\"\ud83d\udcca Next step: Use insights for training pipeline in notebook 11\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}