{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# \ud83d\ude80 Snowflake ML Platform: Unified Training Pipeline\n",
    "\n",
    "This notebook implements a production-ready training pipeline that sources features from the feature store and trains both supervised and unsupervised models in a unified workflow.\n",
    "\n",
    "## \ud83c\udfaf What We're Building\n",
    "- **Feature Store Integration**: Source all features from centralized feature store\n",
    "- **Supervised ML**: Advanced adverse event prediction models (XGBoost + Random Forest)\n",
    "- **Unsupervised ML**: Patient segmentation and anomaly detection\n",
    "- **Model Comparison**: Automated model selection and performance comparison\n",
    "- **Pipeline Orchestration**: End-to-end training workflow automation\n",
    "- **Model Registry**: Automated model registration and versioning\n",
    "\n",
    "## \ud83c\udfd7\ufe0f Training Pipeline Architecture\n",
    "```\n",
    "Feature Store \u2192 Feature Loading \u2192 Data Preparation\n",
    "     \u2193                \u2193               \u2193\n",
    "Model Training \u2192 Model Evaluation \u2192 Model Registry\n",
    "     \u2193                \u2193               \u2193\n",
    "Supervised ML    Performance      Version Control\n",
    "Unsupervised ML  Comparison       Metadata Tracking\n",
    "```\n",
    "\n",
    "## \ud83c\udfaf Enterprise Benefits\n",
    "- **Consistency**: Same features for all models (eliminates train/serve skew)\n",
    "- **Automation**: Fully automated training pipeline with minimal manual intervention\n",
    "- **Reproducibility**: Version-controlled models with complete lineage tracking\n",
    "- **Scalability**: Distributed training across Snowflake's elastic compute\n",
    "- **Governance**: Centralized model management with approval workflows\n",
    "- **Efficiency**: Reusable training components across multiple models\n",
    "\n",
    "## \ud83c\udfe5 Healthcare-Specific Value\n",
    "- **Multi-Model Insights**: Combine supervised predictions with unsupervised insights\n",
    "- **Clinical Validation**: Automated model performance benchmarking\n",
    "- **Risk Stratification**: Integrated patient segmentation and risk scoring\n",
    "- **Regulatory Compliance**: Complete model lineage and audit trails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for unified training pipeline\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, lit, current_timestamp, when\n",
    "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.cluster import KMeans\n",
    "from snowflake.ml.modeling.ensemble import IsolationForest\n",
    "from snowflake.ml.modeling.preprocessing import StandardScaler\n",
    "from snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from snowflake.ml.registry import Model\n",
    "import datetime\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "print(\"\ud83d\ude80 Training Pipeline Libraries Loaded!\")\n",
    "print(\"\ud83d\udd17 Ready for unified ML training from Feature Store\")\n",
    "\n",
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context for training pipeline\n",
    "session.use_database(\"ADVERSE_EVENT_MONITORING\")\n",
    "session.use_warehouse(\"ADVERSE_EVENT_WH\")\n",
    "\n",
    "print(\"\u2705 Session configured for training pipeline\")\n",
    "print(f\"\ud83d\udccd Database: {session.get_current_database()}\")\n",
    "print(f\"\ud83d\udccd Warehouse: {session.get_current_warehouse()}\")\n",
    "\n",
    "# Try to use GPU compute pool for XGBoost (with fallback)\n",
    "try:\n",
    "    session.sql(\"USE WAREHOUSE ML_GPU_POOL\").collect()\n",
    "    print(f\"\ud83d\udd25 Using GPU compute pool for accelerated training\")\n",
    "    gpu_available = True\n",
    "except:\n",
    "    print(f\"\ud83d\udcbb Using standard warehouse (GPU pool not available)\")\n",
    "    gpu_available = False\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udfea Loading Training Data from Feature Store...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load features from the centralized feature store\n",
    "session.use_schema(\"FEATURE_STORE\")\n",
    "\n",
    "try:\n",
    "    # Load training features from offline feature store\n",
    "    training_data = session.table(\"OFFLINE_FEATURE_STORE\")\n",
    "    total_records = training_data.count()\n",
    "    \n",
    "    print(f\"\u2705 Loaded training data from feature store: {total_records} patient records\")\n",
    "    \n",
    "    # Define feature sets for different model types\n",
    "    demographic_features = [\"patient_age\"]\n",
    "    \n",
    "    claims_features = [\n",
    "        \"total_claim_amount_sum\",\n",
    "        \"num_claims\", \n",
    "        \"avg_claim_amount\",\n",
    "        \"claims_last_30d\",\n",
    "        \"claims_last_90d\"\n",
    "    ]\n",
    "    \n",
    "    medical_features = [\n",
    "        \"num_conditions\",\n",
    "        \"num_medications\",\n",
    "        \"chronic_conditions_count\"\n",
    "    ]\n",
    "    \n",
    "    risk_features = [\n",
    "        \"comorbidity_score\",\n",
    "        \"medication_complexity_score\", \n",
    "        \"healthcare_utilization_score\"\n",
    "    ]\n",
    "    \n",
    "    # Complete feature set for supervised learning\n",
    "    supervised_features = demographic_features + claims_features + medical_features + risk_features\n",
    "    \n",
    "    # Feature set for unsupervised learning (excluding target)\n",
    "    unsupervised_features = supervised_features.copy()\n",
    "    \n",
    "    target_variable = \"adverse_event_target\"\n",
    "    \n",
    "    print(f\"\ud83d\udcca Feature Set Configuration:\")\n",
    "    print(f\"   \ud83d\udc64 Demographics: {len(demographic_features)} features\")\n",
    "    print(f\"   \ud83d\udcb0 Claims: {len(claims_features)} features\") \n",
    "    print(f\"   \ud83c\udfe5 Medical: {len(medical_features)} features\")\n",
    "    print(f\"   \ud83d\udcc8 Risk Scores: {len(risk_features)} features\")\n",
    "    print(f\"   \ud83c\udfaf Total Supervised Features: {len(supervised_features)}\")\n",
    "    print(f\"   \ud83e\udde0 Total Unsupervised Features: {len(unsupervised_features)}\")\n",
    "    \n",
    "    # Prepare clean training dataset\n",
    "    clean_training_data = training_data.select(\n",
    "        col(\"entity_id\").alias(\"patient_id\"),\n",
    "        *[col(feature) for feature in supervised_features],\n",
    "        col(target_variable).alias(\"target\")\n",
    "    ).filter(\n",
    "        # Remove rows with null values for robust training\n",
    "        col(\"patient_age\").isNotNull() &\n",
    "        col(\"total_claim_amount_sum\").isNotNull() &\n",
    "        col(\"target\").isNotNull()\n",
    "    )\n",
    "    \n",
    "    clean_count = clean_training_data.count()\n",
    "    print(f\"\u2705 Prepared clean training dataset: {clean_count} patients\")\n",
    "    \n",
    "    # Show data quality metrics\n",
    "    target_distribution = clean_training_data.group_by(\"target\").agg(\n",
    "        col(\"target\").count().alias(\"count\")\n",
    "    ).collect()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Training Data Quality Metrics:\")\n",
    "    for row in target_distribution:\n",
    "        target_val = row[\"TARGET\"]\n",
    "        count = row[\"COUNT\"]\n",
    "        percentage = (count / clean_count) * 100\n",
    "        label = \"Adverse Event\" if target_val else \"No Adverse Event\"\n",
    "        print(f\"   \u2022 {label}: {count} patients ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Calculate class balance\n",
    "    positive_cases = sum(row[\"COUNT\"] for row in target_distribution if row[\"TARGET\"])\n",
    "    negative_cases = sum(row[\"COUNT\"] for row in target_distribution if not row[\"TARGET\"])\n",
    "    class_ratio = negative_cases / positive_cases if positive_cases > 0 else 1\n",
    "    \n",
    "    print(f\"   \u2022 Class Imbalance Ratio: {class_ratio:.1f}:1 (negative:positive)\")\n",
    "    \n",
    "    # Show feature statistics\n",
    "    feature_stats = clean_training_data.select(\n",
    "        col(\"patient_age\").avg().alias(\"avg_age\"),\n",
    "        col(\"total_claim_amount_sum\").avg().alias(\"avg_claims\"),\n",
    "        col(\"num_conditions\").avg().alias(\"avg_conditions\"),\n",
    "        col(\"comorbidity_score\").avg().alias(\"avg_comorbidity\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcc8 Feature Statistics:\")\n",
    "    print(f\"   \u2022 Average Age: {feature_stats['AVG_AGE']:.1f} years\")\n",
    "    print(f\"   \u2022 Average Claims: ${feature_stats['AVG_CLAIMS']:,.0f}\")\n",
    "    print(f\"   \u2022 Average Conditions: {feature_stats['AVG_CONDITIONS']:.1f}\")\n",
    "    print(f\"   \u2022 Average Comorbidity Score: {feature_stats['AVG_COMORBIDITY']:.2f}\")\n",
    "    \n",
    "    # Split data for training and testing\n",
    "    print(f\"\\n\ud83d\udcca Splitting Data for Training and Validation...\")\n",
    "    train_data, test_data = clean_training_data.random_split([0.8, 0.2], seed=42)\n",
    "    \n",
    "    train_count = train_data.count()\n",
    "    test_count = test_data.count()\n",
    "    \n",
    "    print(f\"   \u2022 Training Set: {train_count} patients ({(train_count/clean_count)*100:.1f}%)\")\n",
    "    print(f\"   \u2022 Test Set: {test_count} patients ({(test_count/clean_count)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n\u2705 Feature Store integration successful - ready for training!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading from feature store: {e}\")\n",
    "    print(\"\ud83d\udca1 Make sure you've run notebooks 09 (Feature Store) and 10 (Unsupervised ML)\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83c\udfaf Supervised ML Training: Adverse Event Prediction...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store training results for comparison\n",
    "training_results = {}\n",
    "\n",
    "# Train XGBoost Model (with GPU acceleration if available)\n",
    "print(\"\ud83d\udd25 Training XGBoost Model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Configure XGBoost with healthcare-optimized parameters\n",
    "    xgb_params = {\n",
    "        'n_estimators': 200,\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'scale_pos_weight': class_ratio,  # Handle class imbalance\n",
    "        'eval_metric': 'auc',\n",
    "        'early_stopping_rounds': 10,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Add GPU-specific parameters if available\n",
    "    if gpu_available:\n",
    "        xgb_params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'gpu_id': 0\n",
    "        })\n",
    "        print(\"   \ud83d\ude80 Using GPU acceleration for XGBoost training\")\n",
    "    \n",
    "    # Initialize XGBoost classifier\n",
    "    xgb_model = XGBClassifier(\n",
    "        input_cols=supervised_features,\n",
    "        output_cols=[\"XGB_PREDICTION\"],\n",
    "        label_cols=[\"target\"],\n",
    "        **xgb_params\n",
    "    )\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    fitted_xgb = xgb_model.fit(train_data)\n",
    "    xgb_training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\u2705 XGBoost training completed in {xgb_training_time:.1f} seconds\")\n",
    "    \n",
    "    # Evaluate XGBoost model\n",
    "    xgb_predictions = fitted_xgb.predict(test_data)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    xgb_accuracy = accuracy_score(df=xgb_predictions, y_true_col_names=\"target\", y_pred_col_names=\"XGB_PREDICTION\")\n",
    "    xgb_precision = precision_score(df=xgb_predictions, y_true_col_names=\"target\", y_pred_col_names=\"XGB_PREDICTION\")\n",
    "    xgb_recall = recall_score(df=xgb_predictions, y_true_col_names=\"target\", y_pred_col_names=\"XGB_PREDICTION\")\n",
    "    xgb_f1 = f1_score(df=xgb_predictions, y_true_col_names=\"target\", y_pred_col_names=\"XGB_PREDICTION\")\n",
    "    \n",
    "    # Store results\n",
    "    training_results['XGBoost'] = {\n",
    "        'model': fitted_xgb,\n",
    "        'predictions': xgb_predictions,\n",
    "        'accuracy': xgb_accuracy,\n",
    "        'precision': xgb_precision,\n",
    "        'recall': xgb_recall,\n",
    "        'f1_score': xgb_f1,\n",
    "        'training_time': xgb_training_time,\n",
    "        'model_type': 'XGBoost'\n",
    "    }\n",
    "    \n",
    "    print(f\"\ud83d\udcca XGBoost Performance:\")\n",
    "    print(f\"   \u2022 Accuracy: {xgb_accuracy:.4f}\")\n",
    "    print(f\"   \u2022 Precision: {xgb_precision:.4f}\")\n",
    "    print(f\"   \u2022 Recall: {xgb_recall:.4f}\")\n",
    "    print(f\"   \u2022 F1-Score: {xgb_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c XGBoost training failed: {e}\")\n",
    "    training_results['XGBoost'] = None\n",
    "\n",
    "# Train Random Forest Model (for comparison)\n",
    "print(f\"\\n\ud83c\udf32 Training Random Forest Model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Initialize Random Forest classifier\n",
    "    rf_model = RandomForestClassifier(\n",
    "        input_cols=supervised_features,\n",
    "        output_cols=[\"RF_PREDICTION\"],\n",
    "        label_cols=[\"target\"],\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    fitted_rf = rf_model.fit(train_data)\n",
    "    rf_training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\u2705 Random Forest training completed in {rf_training_time:.1f} seconds\")\n",
    "    \n",
    "    # Evaluate Random Forest model\n",
    "    rf_predictions = fitted_rf.predict(test_data)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rf_accuracy = accuracy_score(df=rf_predictions, y_true_col_names=\"target\", y_pred_col_names=\"RF_PREDICTION\")\n",
    "    rf_precision = precision_score(df=rf_predictions, y_true_col_names=\"target\", y_pred_col_names=\"RF_PREDICTION\")\n",
    "    rf_recall = recall_score(df=rf_predictions, y_true_col_names=\"target\", y_pred_col_names=\"RF_PREDICTION\")\n",
    "    rf_f1 = f1_score(df=rf_predictions, y_true_col_names=\"target\", y_pred_col_names=\"RF_PREDICTION\")\n",
    "    \n",
    "    # Store results\n",
    "    training_results['RandomForest'] = {\n",
    "        'model': fitted_rf,\n",
    "        'predictions': rf_predictions,\n",
    "        'accuracy': rf_accuracy,\n",
    "        'precision': rf_precision,\n",
    "        'recall': rf_recall,\n",
    "        'f1_score': rf_f1,\n",
    "        'training_time': rf_training_time,\n",
    "        'model_type': 'RandomForest'\n",
    "    }\n",
    "    \n",
    "    print(f\"\ud83d\udcca Random Forest Performance:\")\n",
    "    print(f\"   \u2022 Accuracy: {rf_accuracy:.4f}\")\n",
    "    print(f\"   \u2022 Precision: {rf_precision:.4f}\")\n",
    "    print(f\"   \u2022 Recall: {rf_recall:.4f}\")\n",
    "    print(f\"   \u2022 F1-Score: {rf_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Random Forest training failed: {e}\")\n",
    "    training_results['RandomForest'] = None\n",
    "\n",
    "# Model Comparison and Selection\n",
    "print(f\"\\n\ud83c\udfc6 Model Performance Comparison:\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "for model_name, results in training_results.items():\n",
    "    if results is not None:\n",
    "        f1 = results['f1_score']\n",
    "        training_time = results['training_time']\n",
    "        \n",
    "        print(f\"\\n\ud83d\udcca {model_name} Summary:\")\n",
    "        print(f\"   \ud83c\udfaf F1-Score: {f1:.4f}\")\n",
    "        print(f\"   \u26a1 Training Time: {training_time:.1f}s\")\n",
    "        print(f\"   \ud83d\udcc8 Accuracy: {results['accuracy']:.4f}\")\n",
    "        print(f\"   \ud83d\udd0d Precision: {results['precision']:.4f}\")\n",
    "        print(f\"   \ud83d\udcca Recall: {results['recall']:.4f}\")\n",
    "        \n",
    "        # Select best model based on F1-score (important for healthcare)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = results\n",
    "            best_model_name = model_name\n",
    "\n",
    "if best_model:\n",
    "    print(f\"\\n\ud83e\udd47 Best Model: {best_model_name}\")\n",
    "    print(f\"   \ud83c\udfc6 F1-Score: {best_f1:.4f}\")\n",
    "    print(f\"   \ud83d\udca1 Selected for deployment based on balanced performance\")\n",
    "else:\n",
    "    print(f\"\\n\u274c No models trained successfully\")\n",
    "\n",
    "print(f\"\\n\u2705 Supervised ML training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83e\udde0 Unsupervised ML Training: Patient Segmentation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train unsupervised models for additional insights\n",
    "unsupervised_results = {}\n",
    "\n",
    "# Prepare data for unsupervised learning (no target variable)\n",
    "unsupervised_data = clean_training_data.select(\n",
    "    \"patient_id\",\n",
    "    *unsupervised_features\n",
    ")\n",
    "\n",
    "# Feature scaling for unsupervised learning\n",
    "print(\"\u2699\ufe0f Scaling features for unsupervised learning...\")\n",
    "\n",
    "try:\n",
    "    # Initialize and apply StandardScaler\n",
    "    scaler = StandardScaler(\n",
    "        input_cols=unsupervised_features,\n",
    "        output_cols=[f\"{feature}_SCALED\" for feature in unsupervised_features]\n",
    "    )\n",
    "    \n",
    "    scaled_unsupervised_data = scaler.fit(unsupervised_data).transform(unsupervised_data)\n",
    "    scaled_features = [f\"{feature}_SCALED\" for feature in unsupervised_features]\n",
    "    \n",
    "    print(f\"\u2705 Feature scaling completed\")\n",
    "    \n",
    "    # Train K-Means clustering for patient segmentation\n",
    "    print(f\"\\n\ud83c\udfaf Training K-Means clustering...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    kmeans = KMeans(\n",
    "        n_clusters=4,  # Healthcare risk segments: Low, Medium, High, Critical\n",
    "        input_cols=scaled_features,\n",
    "        output_cols=[\"CLUSTER_ID\"],\n",
    "        random_state=42,\n",
    "        max_iter=100\n",
    "    )\n",
    "    \n",
    "    fitted_kmeans = kmeans.fit(scaled_unsupervised_data)\n",
    "    clustering_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\u2705 K-Means clustering completed in {clustering_time:.1f} seconds\")\n",
    "    \n",
    "    # Apply clustering\n",
    "    clustered_data = fitted_kmeans.predict(scaled_unsupervised_data)\n",
    "    \n",
    "    # Analyze cluster characteristics\n",
    "    cluster_analysis = clustered_data.group_by(\"CLUSTER_ID\").agg(\n",
    "        col(\"patient_id\").count().alias(\"patient_count\"),\n",
    "        col(\"patient_age\").avg().alias(\"avg_age\"),\n",
    "        col(\"comorbidity_score\").avg().alias(\"avg_comorbidity\"),\n",
    "        col(\"healthcare_utilization_score\").avg().alias(\"avg_utilization\")\n",
    "    ).collect()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Patient Cluster Analysis:\")\n",
    "    for cluster in cluster_analysis:\n",
    "        cluster_id = cluster[\"CLUSTER_ID\"]\n",
    "        count = cluster[\"PATIENT_COUNT\"]\n",
    "        avg_age = cluster[\"AVG_AGE\"] \n",
    "        avg_comorbidity = cluster[\"AVG_COMORBIDITY\"]\n",
    "        \n",
    "        risk_levels = [\"\ud83d\udfe2 LOW\", \"\ud83d\udfe1 MEDIUM\", \"\ud83d\udfe0 HIGH\", \"\ud83d\udd34 CRITICAL\"]\n",
    "        risk_level = risk_levels[min(cluster_id, 3)]\n",
    "        \n",
    "        print(f\"   Cluster {cluster_id} ({risk_level}): {count} patients, Age: {avg_age:.1f}, Comorbidity: {avg_comorbidity:.2f}\")\n",
    "    \n",
    "    unsupervised_results['KMeans'] = {\n",
    "        'model': fitted_kmeans,\n",
    "        'data': clustered_data,\n",
    "        'training_time': clustering_time,\n",
    "        'n_clusters': 4\n",
    "    }\n",
    "    \n",
    "    # Train Isolation Forest for anomaly detection\n",
    "    print(f\"\\n\ud83d\udea8 Training Isolation Forest for anomaly detection...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    isolation_forest = IsolationForest(\n",
    "        input_cols=scaled_features,\n",
    "        output_cols=[\"ANOMALY_SCORE\"],\n",
    "        contamination=0.1,  # Expect ~10% anomalies\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "    \n",
    "    fitted_isolation_forest = isolation_forest.fit(scaled_unsupervised_data)\n",
    "    anomaly_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\u2705 Isolation Forest completed in {anomaly_time:.1f} seconds\")\n",
    "    \n",
    "    # Apply anomaly detection\n",
    "    anomaly_data = fitted_isolation_forest.predict(scaled_unsupervised_data)\n",
    "    \n",
    "    # Count anomalies\n",
    "    anomaly_count = anomaly_data.filter(col(\"ANOMALY_SCORE\") < -0.1).count()\n",
    "    total_patients = anomaly_data.count()\n",
    "    anomaly_rate = (anomaly_count / total_patients) * 100\n",
    "    \n",
    "    print(f\"\ud83d\udcca Anomaly Detection Results:\")\n",
    "    print(f\"   \ud83d\udea8 Anomalous patients: {anomaly_count} ({anomaly_rate:.1f}%)\")\n",
    "    print(f\"   \u2705 Normal patients: {total_patients - anomaly_count} ({100-anomaly_rate:.1f}%)\")\n",
    "    \n",
    "    unsupervised_results['IsolationForest'] = {\n",
    "        'model': fitted_isolation_forest,\n",
    "        'data': anomaly_data,\n",
    "        'training_time': anomaly_time,\n",
    "        'anomaly_count': anomaly_count,\n",
    "        'anomaly_rate': anomaly_rate\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n\u2705 Unsupervised ML training completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Unsupervised ML training failed: {e}\")\n",
    "    print(\"\ud83d\udcdd Continuing with supervised models only...\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Complete Training Pipeline Results:\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "total_training_time = sum(\n",
    "    result['training_time'] for result in training_results.values() if result is not None\n",
    ") + sum(\n",
    "    result['training_time'] for result in unsupervised_results.values() if result is not None\n",
    ")\n",
    "\n",
    "print(f\"\u23f1\ufe0f  Total Training Time: {total_training_time:.1f} seconds\")\n",
    "print(f\"\ud83c\udfaf Supervised Models: {len([r for r in training_results.values() if r is not None])}\")\n",
    "print(f\"\ud83e\udde0 Unsupervised Models: {len([r for r in unsupervised_results.values() if r is not None])}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(f\"\ud83d\udd25 GPU Acceleration: Enabled\")\n",
    "else:\n",
    "    print(f\"\ud83d\udcbb Compute: Standard CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83d\udccb Model Registry Integration...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Register best performing models in Snowflake Model Registry\n",
    "session.use_schema(\"ML_MODELS\")\n",
    "\n",
    "registry_results = {}\n",
    "\n",
    "try:\n",
    "    # Register the best supervised model\n",
    "    if best_model is not None:\n",
    "        print(f\"\ud83d\udcdd Registering best supervised model: {best_model_name}\")\n",
    "        \n",
    "        # Generate unique model version\n",
    "        model_version = f\"v{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        model_name = f\"ADVERSE_EVENT_PREDICTOR_{best_model['model_type'].upper()}\"\n",
    "        \n",
    "        # Prepare model metadata\n",
    "        model_metadata = {\n",
    "            \"description\": f\"{best_model['model_type']} model for adverse health event prediction\",\n",
    "            \"model_type\": \"BINARY_CLASSIFICATION\",\n",
    "            \"target_variable\": \"adverse_event_target\",\n",
    "            \"feature_count\": len(supervised_features),\n",
    "            \"features_used\": supervised_features,\n",
    "            \"training_data_source\": \"FEATURE_STORE.OFFLINE_FEATURE_STORE\",\n",
    "            \"accuracy\": float(best_model['accuracy']),\n",
    "            \"precision\": float(best_model['precision']),\n",
    "            \"recall\": float(best_model['recall']),\n",
    "            \"f1_score\": float(best_model['f1_score']),\n",
    "            \"training_time_seconds\": float(best_model['training_time']),\n",
    "            \"class_imbalance_ratio\": float(class_ratio),\n",
    "            \"gpu_accelerated\": gpu_available,\n",
    "            \"training_date\": str(datetime.datetime.now()),\n",
    "            \"feature_store_version\": \"1.0\",\n",
    "            \"pipeline_version\": \"unified_training_v1.0\"\n",
    "        }\n",
    "        \n",
    "        # Register model in Snowflake Model Registry\n",
    "        registered_model = Model.upload_model(\n",
    "            session=session,\n",
    "            name=model_name,\n",
    "            version=model_version,\n",
    "            model=best_model['model'],\n",
    "            metadata=model_metadata,\n",
    "            comment=f\"Best performing {best_model['model_type']} model from unified training pipeline\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\u2705 Supervised model registered: {model_name} {model_version}\")\n",
    "        print(f\"   \ud83c\udfaf F1-Score: {best_model['f1_score']:.4f}\")\n",
    "        print(f\"   \ud83d\udcca Model ID: {registered_model.model_id}\")\n",
    "        \n",
    "        registry_results['supervised'] = {\n",
    "            'model_name': model_name,\n",
    "            'version': model_version,\n",
    "            'model_id': registered_model.model_id,\n",
    "            'metadata': model_metadata\n",
    "        }\n",
    "        \n",
    "        # Also update custom MODEL_REGISTRY table\n",
    "        session.sql(f\"\"\"\n",
    "            INSERT INTO MODEL_REGISTRY (\n",
    "                model_id, model_name, model_type, model_version, training_date,\n",
    "                accuracy_score, precision_score, recall_score, f1_score, \n",
    "                model_status, created_by\n",
    "            ) VALUES (\n",
    "                '{registered_model.model_id}',\n",
    "                '{model_name}',\n",
    "                'CLASSIFICATION',\n",
    "                '{model_version}',\n",
    "                CURRENT_TIMESTAMP(),\n",
    "                {best_model['accuracy']},\n",
    "                {best_model['precision']},\n",
    "                {best_model['recall']},\n",
    "                {best_model['f1_score']},\n",
    "                'STAGING',\n",
    "                CURRENT_USER()\n",
    "            )\n",
    "        \"\"\").collect()\n",
    "        \n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No supervised model available for registration\")\n",
    "    \n",
    "    # Save unsupervised model results to feature store\n",
    "    if unsupervised_results:\n",
    "        print(f\"\\n\ud83d\udcbe Saving unsupervised ML results...\")\n",
    "        \n",
    "        session.use_schema(\"FEATURE_STORE\")\n",
    "        \n",
    "        # Update the unsupervised ML insights table with new training results\n",
    "        if 'KMeans' in unsupervised_results:\n",
    "            clustering_data = unsupervised_results['KMeans']['data']\n",
    "            \n",
    "            # Save clustering results\n",
    "            clustering_summary = clustering_data.group_by(\"CLUSTER_ID\").agg(\n",
    "                col(\"patient_id\").count().alias(\"patient_count\"),\n",
    "                col(\"patient_age\").avg().alias(\"avg_age\"),\n",
    "                col(\"comorbidity_score\").avg().alias(\"avg_comorbidity\")\n",
    "            ).with_column(\n",
    "                \"training_date\",\n",
    "                lit(datetime.datetime.now())\n",
    "            ).with_column(\n",
    "                \"model_version\",\n",
    "                lit(\"unified_pipeline_v1.0\")\n",
    "            )\n",
    "            \n",
    "            # Create or update clustering insights table\n",
    "            session.sql(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS CLUSTERING_INSIGHTS (\n",
    "                    cluster_id INTEGER,\n",
    "                    patient_count INTEGER,\n",
    "                    avg_age FLOAT,\n",
    "                    avg_comorbidity FLOAT,\n",
    "                    training_date TIMESTAMP,\n",
    "                    model_version VARCHAR(50)\n",
    "                )\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            clustering_summary.write.mode(\"append\").save_as_table(\"CLUSTERING_INSIGHTS\")\n",
    "            print(f\"   \u2705 K-Means clustering insights saved\")\n",
    "        \n",
    "        if 'IsolationForest' in unsupervised_results:\n",
    "            anomaly_rate = unsupervised_results['IsolationForest']['anomaly_rate']\n",
    "            \n",
    "            # Log anomaly detection results\n",
    "            session.sql(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS ANOMALY_DETECTION_LOGS (\n",
    "                    training_date TIMESTAMP,\n",
    "                    anomaly_rate FLOAT,\n",
    "                    total_patients INTEGER,\n",
    "                    model_version VARCHAR(50)\n",
    "                )\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            session.sql(f\"\"\"\n",
    "                INSERT INTO ANOMALY_DETECTION_LOGS VALUES (\n",
    "                    CURRENT_TIMESTAMP(),\n",
    "                    {anomaly_rate},\n",
    "                    {total_patients},\n",
    "                    'unified_pipeline_v1.0'\n",
    "                )\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            print(f\"   \u2705 Anomaly detection results logged\")\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfc6 Training Pipeline Completion Summary:\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"\u2705 Feature Store Integration: Complete\")\n",
    "    print(f\"\u2705 Supervised ML Training: {len([r for r in training_results.values() if r is not None])} models\")\n",
    "    print(f\"\u2705 Unsupervised ML Training: {len([r for r in unsupervised_results.values() if r is not None])} models\")\n",
    "    print(f\"\u2705 Model Registry: {'Complete' if registry_results else 'Partial'}\")\n",
    "    print(f\"\u2705 Total Training Time: {total_training_time:.1f} seconds\")\n",
    "    \n",
    "    if best_model:\n",
    "        print(f\"\\n\ud83c\udfaf Best Model for Deployment:\")\n",
    "        print(f\"   \ud83d\udcdb Name: {best_model_name}\")\n",
    "        print(f\"   \ud83c\udfc6 F1-Score: {best_model['f1_score']:.4f}\")\n",
    "        print(f\"   \ud83d\udcca Model ID: {registry_results.get('supervised', {}).get('model_id', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udccb Next Steps:\")\n",
    "    print(f\"   1. Use `12_Inference_Pipeline` for real-time predictions\")\n",
    "    print(f\"   2. Use `13_ML_Platform_Demo` for complete platform showcase\")\n",
    "    print(f\"   3. Review models in Snowsight Model Registry\")\n",
    "    print(f\"   4. Deploy best model for production inference\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\ude80 Unified Training Pipeline Complete!\")\n",
    "    print(f\"\ud83c\udf89 Ready for production deployment and inference\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error in model registry integration: {e}\")\n",
    "    print(\"\ud83d\udca1 Models trained successfully but registration failed\")\n",
    "    print(\"\ud83d\udcdd Manual registration may be required\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}